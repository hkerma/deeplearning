{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "4caeeb0d-4685-4fc4-ae62-3a28604766ff"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ResNet_pruning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdc44b8fa9e54ae6b6fb393c79f53a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fce4999078e4129adf77fe0ec743d5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bc2505e315446658e274499ee970419",
              "IPY_MODEL_2439bbbb941d4382b72c1b145d8a5178"
            ]
          }
        },
        "2fce4999078e4129adf77fe0ec743d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bc2505e315446658e274499ee970419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71ba8f30970140bdb70624164c3852f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bd9ca46b36049c291ce356883e457e4"
          }
        },
        "2439bbbb941d4382b72c1b145d8a5178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b87f274a1fc34c29a2e6935bc5ec30b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 17629155.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a33c4148547f4f4595c73a65aff63b6a"
          }
        },
        "71ba8f30970140bdb70624164c3852f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bd9ca46b36049c291ce356883e457e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b87f274a1fc34c29a2e6935bc5ec30b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a33c4148547f4f4595c73a65aff63b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53BKQ0sDK1DS",
        "colab_type": "code",
        "outputId": "ab3b54c0-8e0d-4708-bd6f-3a17513097ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "cdc44b8fa9e54ae6b6fb393c79f53a55",
            "2fce4999078e4129adf77fe0ec743d5c",
            "5bc2505e315446658e274499ee970419",
            "2439bbbb941d4382b72c1b145d8a5178",
            "71ba8f30970140bdb70624164c3852f6",
            "4bd9ca46b36049c291ce356883e457e4",
            "b87f274a1fc34c29a2e6935bc5ec30b1",
            "a33c4148547f4f4595c73a65aff63b6a"
          ]
        }
      },
      "source": [
        "n_classes_minicifar = 4\n",
        "R = 5\n",
        "\n",
        "# Download the entire CIFAR10 dataset\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "import numpy as np \n",
        "from torch.utils.data import Subset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "## Normalization is different when training from scratch and when training using an imagenet pretrained backbone\n",
        "\n",
        "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "\n",
        "normalize_forimagenet = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Data augmentation is needed in order to train from scratch\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_scratch,\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_scratch,\n",
        "])\n",
        "\n",
        "## No data augmentation when using Transfer Learning\n",
        "transform_train_imagenet = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_forimagenet,\n",
        "])\n",
        "\n",
        "transform_test_imagenet = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_forimagenet,\n",
        "])\n",
        "\n",
        "\n",
        "### The data from CIFAR10 will be downloaded in the following dataset\n",
        "rootdir = './data/cifar10'\n",
        "\n",
        "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
        "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
        "\n",
        "c10train_imagenet = CIFAR10(rootdir,train=True,download=True,transform=transform_train_imagenet)\n",
        "c10test_imagenet = CIFAR10(rootdir,train=False,download=True,transform=transform_test_imagenet)\n",
        "\n",
        "# Generating Mini-CIFAR\n",
        "# \n",
        "# CIFAR10 is sufficiently large so that training a model up to the state of the art performance will take approximately 3 hours on the 1060 GPU available on your machine. \n",
        "# As a result, we will create a \"MiniCifar\" dataset, based on CIFAR10, with less classes and exemples. \n",
        "\n",
        "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
        "\n",
        "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
        "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
        "\n",
        "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
        "\n",
        "\n",
        "    all_indices = []\n",
        "    for curclas in range(n_classes):\n",
        "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
        "        indices_curclas = curtargets[0]\n",
        "        indices_subset = indices_curclas[indices_split]\n",
        "        #print(len(indices_subset))\n",
        "        all_indices.append(indices_subset)\n",
        "    all_indices = np.hstack(all_indices)\n",
        "    \n",
        "    return Subset(dataset,indices=all_indices)\n",
        "    \n",
        "### These dataloader are ready to be used to train for scratch \n",
        "minicifar_train= generate_subset(dataset=c10train,n_classes=n_classes_minicifar,reducefactor=R,n_ex_class_init=5000)\n",
        "minicifar_val= generate_subset(dataset=c10test,n_classes=n_classes_minicifar,reducefactor=1,n_ex_class_init=1000) \n",
        "minicifar_test= generate_subset(dataset=c10test,n_classes=n_classes_minicifar,reducefactor=1,n_ex_class_init=1000) \n",
        "\n",
        "\n",
        "### These dataloader are ready to be used to train using Transfer Learning \n",
        "### from a backbone pretrained on ImageNet\n",
        "minicifar_train_im= generate_subset(dataset=c10train_imagenet,n_classes=n_classes_minicifar,reducefactor=R,n_ex_class_init=5000)\n",
        "minicifar_val_im= generate_subset(dataset=c10test_imagenet,n_classes=n_classes_minicifar,reducefactor=1,n_ex_class_init=1000)\n",
        "minicifar_test_im= generate_subset(dataset=c10test_imagenet,n_classes=n_classes_minicifar,reducefactor=1,n_ex_class_init=1000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdc44b8fa9e54ae6b6fb393c79f53a55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar10/cifar-10-python.tar.gz to ./data/cifar10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNhgmLN1K1D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, size_factor=64):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = size_factor\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, size_factor, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(size_factor)\n",
        "        self.layer1 = self._make_layer(block, size_factor, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 2*size_factor, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 4*size_factor, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 8*size_factor, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(8*size_factor*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "def ResNetCustom(size_factor, num_classes):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], size_factor=size_factor, num_classes=num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Az3c0nK1EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class PR():\n",
        "    def __init__(self,model,norm):\n",
        "        #Model\n",
        "        self.model = model\n",
        "        self.weak_params = 0.0\n",
        "        self.norm = norm\n",
        "        self.count = 0.0\n",
        "        \n",
        "    #Computer the weight sum for a kernel/filter\n",
        "    #filt = conv2.weight[i][j].data)\n",
        "    def L1(self,kern):\n",
        "        return np.sum(np.abs(kern.cpu().numpy()))\n",
        "\n",
        "    def L2(self,kern):\n",
        "        return np.sqrt(np.sum(np.square(kern.cpu().numpy())))\n",
        "\n",
        "    def Max(self,kern):\n",
        "        return np.max(np.abs(kern.cpu().numpy()))\n",
        "\n",
        "    def Infinity(self,kern):\n",
        "        conv = kern.cpu().numpy()\n",
        "        max_value = 0.0\n",
        "        for c in conv:\n",
        "            temp = np.sum(np.abs(c))\n",
        "            if (temp > max_value):\n",
        "                max_value = temp\n",
        "        return temp\n",
        "\n",
        "    #def sum_weights_layer(self,m):\n",
        "        #input_shape,output_shape = m.in_channels, m.out_channels\n",
        "        #norm_factor = (1/(input_shape*m.kernel_size[0]*m.kernel_size[1]))\n",
        "        #sum_layer = [0]*output_shape\n",
        "        #for j in range(output_shape):\n",
        "            #for i in range(input_shape): \n",
        "                #sum_layer[j] += self.sum_weights(m.weight[j][i].data)\n",
        "            #sum_layer[j] = sum_layer[j]*norm_factor\n",
        "        #Normalize the sum\n",
        "        #return sum_layer\n",
        "    \n",
        "    def sum_weights_layer(self,m,layer_num):\n",
        "        input_shape,output_shape = m.in_channels, m.out_channels\n",
        "        norm_factor = (1/(input_shape*m.kernel_size[0]*m.kernel_size[1]))\n",
        "        sum_layer = []\n",
        "        for j in range(output_shape):\n",
        "            temp,temp_sum = [],0.0\n",
        "            temp.append(layer_num)\n",
        "            temp.append(j)\n",
        "            for i in range(input_shape):\n",
        "                if self.norm == \"L1\":\n",
        "                  temp_sum += self.L1(m.weight[j][i].data)\n",
        "                elif self.norm == \"Max\":\n",
        "                  temp_sum += self.Max(m.weight[j][i].data)\n",
        "                elif self.norm == \"L2\":\n",
        "                  temp_sum += self.L2(m.weight[j][i].data)\n",
        "                elif self.norm == \"Infinity\":\n",
        "                  temp_sum += self.Infinity(m.weight[j][i].data)\n",
        "            if self.norm == \"L1\":\n",
        "                temp_sum = temp_sum*norm_factor\n",
        "            elif self.norm == \"L2\":\n",
        "                temp_sum = temp_sum*norm_factor\n",
        "            elif self.norm == \"Infinity\":\n",
        "                temp_sum = temp_sum*norm_factor*m.kernel_size[0]\n",
        "            temp.append(temp_sum)\n",
        "            sum_layer.append(temp)\n",
        "        return sum_layer\n",
        "    \n",
        "    def sum_weights_filter(self,m,layer_num,filter_num):\n",
        "        input_shape = m.in_channels\n",
        "        sum_filter = []\n",
        "        for i in range(input_shape):\n",
        "            temp,temp_sum = [],0.0\n",
        "            temp.append(layer_num)\n",
        "            temp.append(filter_num)\n",
        "            temp.append(i)\n",
        "            temp.append(self.L1(m.weight[filter_num][i].data))\n",
        "            sum_filter.append(temp)\n",
        "        return sum_filter\n",
        "\n",
        "    def extract_min(self,li,ratio):\n",
        "        new_li = [x for x in li if x[-1] > 0.0]\n",
        "        sor = sorted(new_li, key=lambda x: x[-1])\n",
        "        res = sor[: math.floor(len(li)*ratio)]\n",
        "        return res\n",
        "    \n",
        "    #def extract_min(self,sum_layer, ratio):\n",
        "        #sum_layer_min = sum_layer.copy()\n",
        "        #number_to_pop = math.floor(len(sum_layer)*ratio)\n",
        "        #result = []\n",
        "        #for i in range(number_to_pop):\n",
        "            #sum_layer_min.pop(np.where(sum_layer_min == np.amax(sum_layer_min))[0][0])   \n",
        "        #for i in sum_layer_min:\n",
        "            #result.append(np.where(np.array(sum_layer) == i)[0][0])                    \n",
        "        #return result   \n",
        "    \n",
        "    def zeros_kernel(self,m,weak_filters,index):\n",
        "        weak_filters = [f for f in weak_filters if f[0]==index]\n",
        "        for f in weak_filters:\n",
        "            for i in range(m.in_channels):\n",
        "                    a = torch.from_numpy(np.zeros(m.kernel_size))         \n",
        "                    with torch.no_grad():\n",
        "                        m.weight[f[1]][i].copy_(a)\n",
        "                        self.weak_params += m.kernel_size[0]*m.kernel_size[1]\n",
        "\n",
        "    def zeros_kernels(self,m,weak_kernels,layer_num,filter_num):\n",
        "        weak_k = [k for k in weak_kernels if k[0] == layer_num and k[1] == filter_num]\n",
        "        for k in weak_k:\n",
        "              a = torch.from_numpy(np.zeros(m.kernel_size))         \n",
        "              with torch.no_grad():\n",
        "                    m.weight[k[1]][k[2]].copy_(a)\n",
        "                    self.weak_params += m.kernel_size[0]*m.kernel_size[1] \n",
        "\n",
        "    #Prunning on each layer\n",
        "    def prunning_per_layer(self, ratio):\n",
        "        #Go through model.modules\n",
        "        index = -1\n",
        "        for m in self.model.modules() :\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                index += 1\n",
        "                sum_layer = self.sum_weights_layer(m,index)\n",
        "                weak_filters = self.extract_min(sum_layer, ratio)\n",
        "                self.zeros_kernel(m,weak_filters,index)\n",
        "\n",
        "    #Prunning on all layers               \n",
        "    def prunning_net(self,ratio):\n",
        "        index = -1\n",
        "        filters = []\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                index += 1\n",
        "                filters += self.sum_weights_layer(m,index)\n",
        "        weak_filters = self.extract_min(filters,ratio)\n",
        "        index = -1\n",
        "        for m in self.model.modules():\n",
        "            temp = []\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                index += 1\n",
        "                self.zeros_kernel(m,weak_filters,index)\n",
        "         \n",
        "            \n",
        "    def prunning_kernel(self,ratio):\n",
        "        index =-1\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                index += 1\n",
        "                for i in range(m.out_channels):\n",
        "                    sum_filter = self.sum_weights_filter(m,index,i)\n",
        "                    weak_kernels = self.extract_min(sum_filter,ratio)\n",
        "                    self.zeros_kernels(m,weak_kernels,index,i)\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x45czG5oSmR8",
        "colab_type": "code",
        "outputId": "ef74e6a1-09fa-4d20-dde0-c41a30f29196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = [[1,1],[1,2],[2,1]]\n",
        "b = [x for x in a if x[0]==1]\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 1], [1, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVSP7YKCcgOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "                     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQ1TNMNK1EZ",
        "colab_type": "code",
        "outputId": "f0f97647-02ee-45df-aa23-7854450a8c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torchvision.models\n",
        "\n",
        "model = torchvision.models.resnet18(True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=4,out_channels=5,kernel_size=(3,3))\n",
        "conv2 = nn.Conv2d(in_channels=4,out_channels=5,kernel_size=(3,3))\n",
        "\n",
        "pr = PR(model,\"L1\")\n",
        "ratio = 0.25\n",
        "index = -1\n",
        "for m in [conv1,conv2]:\n",
        "    for n in [1,2,3]:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            index += 1\n",
        "            for i in range(conv1.out_channels):\n",
        "                sum_filter, weak_kernels = [],[]\n",
        "                sum_filter = pr.sum_weights_filter(m,index,i)\n",
        "                weak_kernels = pr.extract_min(sum_filter,ratio)\n",
        "                pr.zeros_kernels(m,weak_kernels,index,i)\n",
        "    \n",
        "#li2 = pr.sum_weights_filter(conv1,0,1)\n",
        "#li3 = pr.sum_weights_filter(conv1,0,2)\n",
        "#li4 = pr.sum_weights_filter(conv1,0,3)\n",
        "#li5 = pr.sum_weights_filter(conv1,0,4)\n",
        "\n",
        "#li3 = pr.sum_weights_filter(conv1,2,2)\n",
        "#print(li,li2)\n",
        "#weak = pr.extract_min(li,0.75)\n",
        "#weak2 = pr.extract_min(li2,0.75)\n",
        "#weak3 = pr.extract_min(li3,0.75)\n",
        "#weak4 = pr.extract_min(li4,0.75)\n",
        "#weak5= pr.extract_min(li5,0.75)\n",
        "\n",
        "\n",
        "#weak3 = pr.extract_min(li3,0.50)\n",
        "#pr.zeros_kernels(conv1,weak,0,0)\n",
        "#pr.zeros_kernels(conv1,weak2,0,1)\n",
        "#pr.zeros_kernels(conv1,weak3,0,2)\n",
        "#pr.zeros_kernels(conv1,weak4,0,3)\n",
        "#pr.zeros_kernels(conv1,weak5,0,4)\n",
        "\n",
        "#pr.zeros_kernels(conv1,weak3,1,2)\n",
        "print(conv1.weight[0])\n",
        "print(conv1.weight[1])\n",
        "print(conv1.weight[2])\n",
        "print(conv1.weight[3])\n",
        "print(conv1.weight[4])\n",
        "\n",
        "print(conv2.weight[0])\n",
        "print(conv2.weight[1])\n",
        "print(conv2.weight[2])\n",
        "print(conv2.weight[3])\n",
        "print(conv2.weight[4])\n",
        "\n",
        "print(pr.weak_params)\n",
        "#print(pr.weak_params)\n",
        "#print(\"Number of paramaters erased : {}\".format((pr.weak_params/p)*100))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.1368,  0.1366,  0.0779],\n",
            "         [ 0.0445, -0.1218, -0.0972],\n",
            "         [ 0.0834,  0.1179,  0.1407]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.1257,  0.1423, -0.1141],\n",
            "         [ 0.1256, -0.0014,  0.0822],\n",
            "         [-0.1156,  0.1484,  0.0799]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.1081,  0.0105,  0.1285],\n",
            "         [ 0.1607,  0.1185, -0.0068],\n",
            "         [-0.0756,  0.1298, -0.0125]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.1469,  0.0374, -0.1529],\n",
            "         [ 0.0575,  0.0051, -0.0511],\n",
            "         [ 0.0291, -0.1153,  0.1010]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.0352, -0.1478,  0.1566],\n",
            "         [ 0.1437, -0.1259, -0.1231],\n",
            "         [ 0.0414, -0.0385, -0.1000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.0606,  0.1191,  0.1413],\n",
            "         [-0.0459,  0.0769, -0.1154],\n",
            "         [-0.1549,  0.1290,  0.1186]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.1376,  0.1371,  0.1494],\n",
            "         [-0.0695,  0.1011,  0.0544],\n",
            "         [-0.0966,  0.0299, -0.1489]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.0399,  0.1619,  0.1033],\n",
            "         [ 0.1091, -0.1605, -0.1111],\n",
            "         [ 0.0975, -0.1370,  0.1221]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[-0.1213,  0.1467,  0.1073],\n",
            "         [-0.0328, -0.0782, -0.0707],\n",
            "         [-0.0878, -0.0941, -0.1106]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<SelectBackward>)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0227, -0.0886,  0.0453],\n",
            "         [-0.1464, -0.0462,  0.1080],\n",
            "         [-0.1612, -0.1505,  0.1032]]], grad_fn=<SelectBackward>)\n",
            "270.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhGuWnmMK1El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "import json\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def main(epoch, iteration, ratios,method, norm):\n",
        "    \n",
        "    batch_size = 32\n",
        "    size_factor = 16\n",
        "    \n",
        "    ### These dataloader are ready to be used to train for scratch \n",
        "    minicifar_train = generate_subset(dataset=c10train,n_classes=n_classes_minicifar,reducefactor=5,n_ex_class_init=5000)\n",
        "    trainloader = DataLoader(minicifar_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    minicifar_test = generate_subset(dataset=c10test,n_classes=n_classes_minicifar,reducefactor=1,n_ex_class_init=1000)\n",
        "    testloader = DataLoader(minicifar_test,batch_size=batch_size, num_workers=2)\n",
        "    minicifar_val = generate_subset(dataset=c10test,n_classes=n_classes_minicifar,reducefactor=5,n_ex_class_init=1000) \n",
        "    valloader = DataLoader(minicifar_val, batch_size=batch_size, num_workers=2)\n",
        "    \n",
        "    accu_final = []\n",
        "\n",
        "    for ratio in ratios:\n",
        "        ### Model is loaded pre-trained\n",
        "        net = ResNetCustom(size_factor=size_factor, num_classes=4)\n",
        "        net.load_state_dict(torch.load('./saved_nn/bs32ep300sf16.pth'))\n",
        "        weights = count_parameters(net)\n",
        "        net.cuda()\n",
        "\n",
        "        prunning_net = PR(net,norm)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "    \n",
        "\n",
        "        correct_test = 0.0\n",
        "        running_loss_test = 0.0\n",
        "        total_test = 0.0\n",
        "        total_weights_removed = 0.0\n",
        "\n",
        "        for it in range(iteration):\n",
        "            \n",
        "            if method == \"prunning_layer\":\n",
        "                prunning_net.prunning_per_layer(ratio)\n",
        "            elif method == \"prunning_net\":\n",
        "                prunning_net.prunning_net(ratio)\n",
        "            elif method == \"prunning_kernel\":\n",
        "                prunning_net.prunning_kernel(ratio)\n",
        "\n",
        "            ###### FINE-TUNING ######\n",
        "            for e in range(epoch):\n",
        "\n",
        "                correct_val = 0.0\n",
        "                running_loss_val = 0.0\n",
        "                total_val = 0.0\n",
        "\n",
        "                net.train()\n",
        "                for _, (data, labels) in enumerate(trainloader):\n",
        "                    #setting to cuda\n",
        "                    data = data.cuda()\n",
        "                    labels = labels.cuda()\n",
        "\n",
        "                    # zero the parameter gradient\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward + backward + optimize\n",
        "                    outputs = net(data)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                net.eval()\n",
        "                for _, (data, labels) in enumerate(valloader):\n",
        "                    #setting to cuda\n",
        "                    data = data.cuda()\n",
        "                    labels = labels.cuda()\n",
        "\n",
        "                    # compute\n",
        "                    outputs = net(data)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # compute statistics\n",
        "                    total_val += labels.size(0)\n",
        "                    running_loss_val += loss.item()\n",
        "                    predicted = outputs.max(1)[1]\n",
        "                    correct_val += predicted.eq(labels).sum().item()\n",
        "                    \n",
        "        ###### RUNNING FINAL TEST ######\n",
        "        net.eval()\n",
        "        for _, (data, labels) in enumerate(testloader):\n",
        "            data = data.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            #Zero the parameter gradient\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(data)\n",
        "            running_loss_test = criterion(outputs,labels)\n",
        "             # compute statistics\n",
        "            total_test += labels.size(0)\n",
        "            running_loss_test += loss.item()\n",
        "            predicted = outputs.max(1)[1]\n",
        "            correct_test += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            ##data = data.cpu()\n",
        "            ##labels = labels.cpu()\n",
        "            ##imshow(torchvision.utils.make_grid(data))\n",
        "            ##print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(10)))\n",
        "            ##print('Predicted: ', ' '.join('%5s' % predicted[j].data for j in range(10)))\n",
        "            ##print('\\n')\n",
        "\n",
        "        \n",
        "        print(\"Method : {} | Norm : {} | Iter : {} | Ratio : {} % | Accuracy  : {} % | Weights Removed : {} %\".format(method,norm,iteration,ratio*100,100*correct_test/total_test, (prunning_net.weak_params/weights)*100))\n",
        "        \n",
        "        accu_final.append(100*correct_test/total_test)\n",
        "        \n",
        "\n",
        "    #### SAVING DATAS ####\n",
        "    personnal_state_dict = {}\n",
        "    personnal_state_dict.update({\"epoch\":epoch, \"iteration\":iteration, \"ratio\":ratios, \"accu\": accu_final, \"method\":method, \"norm\":norm})\n",
        "    \n",
        "    with open('./save/' + 'ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + str(norm) + '.json', 'w') as file:\n",
        "        file.write(json.dumps(personnal_state_dict))\n",
        "        \n",
        "    torch.save(net.state_dict(), './save/' + 'ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + str(norm) + '.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAg0GE87xAhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfPvz06OK1Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "def plot(epoch, iteration, ratio):\n",
        "    \n",
        "    with open('save/ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + str(norm) + '.json', 'r') as file:\n",
        "        text = file.read()\n",
        "        jf = json.loads(text)\n",
        "        \n",
        "        accu = jf[\"accu\"]\n",
        "        ratios = jf[\"ratio\"]        \n",
        "        \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(ratio, accu, '-b', label = \"Accu function of ratio\")\n",
        "\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.text(0.5, 0.4, 'ep' + str(epoch) + 'it' + str(iteration), horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=15)\n",
        "    plt.xlabel(\"Ratio\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    ax.legend()\n",
        "    plt.savefig('accu_' + 'ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + str(norm) + '.pdf')\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwfCLQD5Ftvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_multiple(epoch,iteration,ratio,method,norm):\n",
        "    accu_list = []\n",
        "\n",
        "    for n in norm:\n",
        "      with open('save/ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + n + '.json', 'r') as file:\n",
        "          text = file.read()\n",
        "          jf = json.loads(text)\n",
        "          \n",
        "          accu = jf[\"accu\"]\n",
        "          ratios = jf[\"ratio\"] \n",
        "          accu_list.append(accu)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    index = -1\n",
        "    for a in accu_list:\n",
        "      index += 1\n",
        "      ax.plot(ratio, a, label = \"Accu | Norm : {} | Method {}\".format(norm[index],method))   \n",
        "\n",
        "    plt.title(\"Accuracy for different norms, method : {}\".format(method))\n",
        "    #plt.text(0.5, 0.4, 'ep' + str(epoch) + 'it' + str(iteration), horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=15)\n",
        "    plt.xlabel(\"Ratio\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    ax.legend()\n",
        "    plt.savefig('Methods' + ' accu_' + 'ep' + str(epoch) + 'it' + str(iteration) + 'me' + str(method) + 'no' + str(norm) + '.pdf')\n",
        "\n",
        "    plt.show()   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hCwtZKzUdjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ratio = [1,0.9,0.8,0.7,0.6,0.5,0.45,0.425,0.4,0.35,0.325,0.3,0.25,0.225,0.2,0.15,0.125,0.1,0.05,0.0]\n",
        "ratio = [0.45,0.425,0.40,0.35,0.325,0.30,0.25]\n",
        "norm = [\"L1\"]\n",
        "epoch = 5\n",
        "\n",
        "\n",
        "##for i in iteration:\n",
        "method = \"prunning_net\"\n",
        "#main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "main(epoch,i,ratio, method,\"L1\")\n",
        "#main(epoch,iteration,ratio, method,\"L2\")\n",
        "plot_multiple(epoch,iteration,ratio,method,norm)\n",
        "\n",
        "method = \"prunning_layer\"\n",
        "#main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "main(epoch,i,ratio, method,\"L1\")\n",
        "#main(epoch,iteration,ratio, method,\"L2\")\n",
        "plot_multiple(epoch,iteration,ratio,method,norm)\n",
        "\n",
        "method = \"prunning_kernel\"\n",
        "#main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "main(epoch,i,ratio, method,\"L1\")\n",
        "#main(epoch,iteration,ratio, method,\"L2\")\n",
        "plot_multiple(epoch,iteration,ratio,method,norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2WoXcXK1E2",
        "colab_type": "code",
        "outputId": "9028e0f4-634e-47b4-a651-015de4b19ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "#ratio = [1,0.9,0.8,0.7,0.6,0.5,0.45,0.425,0.4,0.35,0.325,0.3,0.25,0.225,0.2,0.15,0.125,0.1,0.05,0.0]\n",
        "#ratio = [0.45,0.425,0.40,0.35,0.325,0.30,0.25]\n",
        "norm = [\"L1\"]\n",
        "ratio = [0.1]\n",
        "epoch = 5\n",
        "iteration = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "\n",
        "##for i in iteration:\n",
        "    #method = \"prunning_net\"\n",
        "    #main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "    #main(epoch,i,ratio, method,\"L1\")\n",
        "    #main(epoch,iteration,ratio, method,\"L2\")\n",
        "\n",
        "method = \"prunning_layer\"\n",
        "for i in iteration:\n",
        "    #main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "    main(epoch,i,ratio, method,\"L1\")\n",
        "    #main(epoch,iteration,ratio, method,\"L2\")\n",
        "\n",
        "method = \"prunning_kernel\"\n",
        "for i in iteration:\n",
        "    #main(epoch,iteration,ratio, method,\"Infinity\")\n",
        "    main(epoch,i,ratio, method,\"L1\")\n",
        "    #main(epoch,iteration,ratio, method,\"L2\")\n",
        "    plot_multiple(epoch,iteration,ratio,method,norm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Method : prunning_layer | Norm : L1 | Iter : 1 | Ratio : 10.0 % | Accuracy  : 79.375 % | Weights Removed : 9.29295610624925 %\n",
            "Method : prunning_layer | Norm : L1 | Iter : 2 | Ratio : 10.0 % | Accuracy  : 79.6 % | Weights Removed : 18.5859122124985 %\n",
            "Method : prunning_layer | Norm : L1 | Iter : 3 | Ratio : 10.0 % | Accuracy  : 77.15 % | Weights Removed : 27.878868318747752 %\n",
            "Method : prunning_layer | Norm : L1 | Iter : 4 | Ratio : 10.0 % | Accuracy  : 81.075 % | Weights Removed : 37.171824424997 %\n",
            "Method : prunning_layer | Norm : L1 | Iter : 5 | Ratio : 10.0 % | Accuracy  : 83.6 % | Weights Removed : 46.464780531246255 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPIcN9_EK1E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IDEAS : \n",
        "# Pruning sur les couches du dÃ©but ? sur les couches de fin ?\n",
        "# Pruning sur l'ensemble des filtres du Net DONE\n",
        "# Jouer sur la norme DONE\n",
        "## imgshow aprÃ¨s la premiÃ¨re couche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKuPF5DPK1FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}