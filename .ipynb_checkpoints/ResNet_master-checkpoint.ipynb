{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "### WIDE RESNET IMPLEMENTATION ###\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class wide_basic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_basic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4)/6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
    "        nStages = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = conv3x3(3,nStages[0])\n",
    "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
    "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
    "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net=Wide_ResNet(28, 10, 0.3, 10)\n",
    "    y = net(Variable(torch.randn(1,3,32,32)))\n",
    "\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Pytorch CIFAR configuration file ###############\n",
    "import math\n",
    "\n",
    "start_epoch = 1\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "optim_type = 'SGD'\n",
    "\n",
    "mean = {\n",
    "    'cifar10': (0.4914, 0.4822, 0.4465),\n",
    "    'cifar100': (0.5071, 0.4867, 0.4408),\n",
    "}\n",
    "\n",
    "std = {\n",
    "    'cifar10': (0.2023, 0.1994, 0.2010),\n",
    "    'cifar100': (0.2675, 0.2565, 0.2761),\n",
    "}\n",
    "\n",
    "# Only for cifar-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if(epoch > 160):\n",
    "        optim_factor = 3\n",
    "    elif(epoch > 120):\n",
    "        optim_factor = 2\n",
    "    elif(epoch > 60):\n",
    "        optim_factor = 1\n",
    "\n",
    "    return init*math.pow(0.2, optim_factor)\n",
    "\n",
    "def get_hms(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "\n",
    "    return h, m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Phase 1] : Data Preparation\n",
      "| Preparing CIFAR-10 dataset...\n",
      "| Files already downloaded and verified\n",
      "| Wide-Resnet 40x2\n",
      "\n",
      "[Phase 2] : Model setup\n",
      "| Building net type [wide-resnet]...\n",
      "| Going fast AF with C U D A *o* !\n",
      "\n",
      "[Phase 3] : Training model\n",
      "| Training Epochs = 200\n",
      "| Initial Learning Rate = 0.1\n",
      "| Optimizer = SGD\n",
      "\n",
      "=> Training Epoch #1, LR=0.1000\n",
      "| Epoch [  1/200] Iter[391/391]\t\tLoss: 1.2877 Acc@1: 38.544%\n",
      "| Validation Epoch #1\t\t\tLoss: 1.4315 Acc@1: 51.48%\n",
      "| Saving Best model...\t\t\tTop1 = 51.48%\n",
      "| Elapsed time : 0:00:59\n",
      "\n",
      "=> Training Epoch #2, LR=0.1000\n",
      "| Epoch [  2/200] Iter[391/391]\t\tLoss: 0.9578 Acc@1: 58.736%\n",
      "| Validation Epoch #2\t\t\tLoss: 1.1576 Acc@1: 60.03%\n",
      "| Saving Best model...\t\t\tTop1 = 60.03%\n",
      "| Elapsed time : 0:01:58\n",
      "\n",
      "=> Training Epoch #3, LR=0.1000\n",
      "| Epoch [  3/200] Iter[391/391]\t\tLoss: 0.7840 Acc@1: 65.484%\n",
      "| Validation Epoch #3\t\t\tLoss: 1.0964 Acc@1: 64.01%\n",
      "| Saving Best model...\t\t\tTop1 = 64.01%\n",
      "| Elapsed time : 0:02:58\n",
      "\n",
      "=> Training Epoch #4, LR=0.1000\n",
      "| Epoch [  4/200] Iter[391/391]\t\tLoss: 0.7844 Acc@1: 69.770%\n",
      "| Validation Epoch #4\t\t\tLoss: 1.1846 Acc@1: 67.05%\n",
      "| Saving Best model...\t\t\tTop1 = 67.05%\n",
      "| Elapsed time : 0:03:57\n",
      "\n",
      "=> Training Epoch #5, LR=0.1000\n",
      "| Epoch [  5/200] Iter[391/391]\t\tLoss: 0.7089 Acc@1: 73.148%\n",
      "| Validation Epoch #5\t\t\tLoss: 0.7648 Acc@1: 72.19%\n",
      "| Saving Best model...\t\t\tTop1 = 72.19%\n",
      "| Elapsed time : 0:04:55\n",
      "\n",
      "=> Training Epoch #6, LR=0.1000\n",
      "| Epoch [  6/200] Iter[391/391]\t\tLoss: 0.7609 Acc@1: 75.614%\n",
      "| Validation Epoch #6\t\t\tLoss: 1.1533 Acc@1: 66.76%\n",
      "| Elapsed time : 0:05:54\n",
      "\n",
      "=> Training Epoch #7, LR=0.1000\n",
      "| Epoch [  7/200] Iter[391/391]\t\tLoss: 0.7663 Acc@1: 77.028%\n",
      "| Validation Epoch #7\t\t\tLoss: 0.9373 Acc@1: 72.57%\n",
      "| Saving Best model...\t\t\tTop1 = 72.57%\n",
      "| Elapsed time : 0:06:53\n",
      "\n",
      "=> Training Epoch #8, LR=0.1000\n",
      "| Epoch [  8/200] Iter[391/391]\t\tLoss: 0.5628 Acc@1: 78.494%\n",
      "| Validation Epoch #8\t\t\tLoss: 0.7367 Acc@1: 74.47%\n",
      "| Saving Best model...\t\t\tTop1 = 74.47%\n",
      "| Elapsed time : 0:07:54\n",
      "\n",
      "=> Training Epoch #9, LR=0.1000\n",
      "| Epoch [  9/200] Iter[391/391]\t\tLoss: 0.6930 Acc@1: 79.368%\n",
      "| Validation Epoch #9\t\t\tLoss: 0.8829 Acc@1: 69.55%\n",
      "| Elapsed time : 0:08:55\n",
      "\n",
      "=> Training Epoch #10, LR=0.1000\n",
      "| Epoch [ 10/200] Iter[391/391]\t\tLoss: 0.7761 Acc@1: 80.000%\n",
      "| Validation Epoch #10\t\t\tLoss: 0.8186 Acc@1: 73.20%\n",
      "| Elapsed time : 0:09:56\n",
      "\n",
      "=> Training Epoch #11, LR=0.1000\n",
      "| Epoch [ 11/200] Iter[391/391]\t\tLoss: 0.6143 Acc@1: 80.288%\n",
      "| Validation Epoch #11\t\t\tLoss: 0.7004 Acc@1: 79.48%\n",
      "| Saving Best model...\t\t\tTop1 = 79.48%\n",
      "| Elapsed time : 0:10:57\n",
      "\n",
      "=> Training Epoch #12, LR=0.1000\n",
      "| Epoch [ 12/200] Iter[391/391]\t\tLoss: 0.4775 Acc@1: 81.014%\n",
      "| Validation Epoch #12\t\t\tLoss: 0.5619 Acc@1: 80.43%\n",
      "| Saving Best model...\t\t\tTop1 = 80.43%\n",
      "| Elapsed time : 0:11:58\n",
      "\n",
      "=> Training Epoch #13, LR=0.1000\n",
      "| Epoch [ 13/200] Iter[391/391]\t\tLoss: 0.5336 Acc@1: 81.674%\n",
      "| Validation Epoch #13\t\t\tLoss: 0.8055 Acc@1: 73.45%\n",
      "| Elapsed time : 0:12:58\n",
      "\n",
      "=> Training Epoch #14, LR=0.1000\n",
      "| Epoch [ 14/200] Iter[391/391]\t\tLoss: 0.4585 Acc@1: 81.674%\n",
      "| Validation Epoch #14\t\t\tLoss: 0.7947 Acc@1: 75.51%\n",
      "| Elapsed time : 0:13:59\n",
      "\n",
      "=> Training Epoch #15, LR=0.1000\n",
      "| Epoch [ 15/200] Iter[391/391]\t\tLoss: 0.6471 Acc@1: 82.172%\n",
      "| Validation Epoch #15\t\t\tLoss: 0.8374 Acc@1: 75.35%\n",
      "| Elapsed time : 0:15:00\n",
      "\n",
      "=> Training Epoch #16, LR=0.1000\n",
      "| Epoch [ 16/200] Iter[391/391]\t\tLoss: 0.4545 Acc@1: 82.266%\n",
      "| Validation Epoch #16\t\t\tLoss: 0.6809 Acc@1: 75.74%\n",
      "| Elapsed time : 0:16:00\n",
      "\n",
      "=> Training Epoch #17, LR=0.1000\n",
      "| Epoch [ 17/200] Iter[391/391]\t\tLoss: 0.5821 Acc@1: 82.632%\n",
      "| Validation Epoch #17\t\t\tLoss: 0.5677 Acc@1: 80.13%\n",
      "| Elapsed time : 0:16:59\n",
      "\n",
      "=> Training Epoch #18, LR=0.1000\n",
      "| Epoch [ 18/200] Iter[391/391]\t\tLoss: 0.6692 Acc@1: 82.904%\n",
      "| Validation Epoch #18\t\t\tLoss: 0.6047 Acc@1: 73.30%\n",
      "| Elapsed time : 0:17:58\n",
      "\n",
      "=> Training Epoch #19, LR=0.1000\n",
      "| Epoch [ 19/200] Iter[391/391]\t\tLoss: 0.5221 Acc@1: 83.224%\n",
      "| Validation Epoch #19\t\t\tLoss: 0.6158 Acc@1: 75.82%\n",
      "| Elapsed time : 0:18:56\n",
      "\n",
      "=> Training Epoch #20, LR=0.1000\n",
      "| Epoch [ 20/200] Iter[391/391]\t\tLoss: 0.6138 Acc@1: 83.120%\n",
      "| Validation Epoch #20\t\t\tLoss: 0.9154 Acc@1: 74.19%\n",
      "| Elapsed time : 0:19:56\n",
      "\n",
      "=> Training Epoch #21, LR=0.1000\n",
      "| Epoch [ 21/200] Iter[391/391]\t\tLoss: 0.4366 Acc@1: 83.944%\n",
      "| Validation Epoch #21\t\t\tLoss: 0.7085 Acc@1: 77.83%\n",
      "| Elapsed time : 0:20:55\n",
      "\n",
      "=> Training Epoch #22, LR=0.1000\n",
      "| Epoch [ 22/200] Iter[391/391]\t\tLoss: 0.4085 Acc@1: 83.676%\n",
      "| Validation Epoch #22\t\t\tLoss: 0.5713 Acc@1: 80.83%\n",
      "| Saving Best model...\t\t\tTop1 = 80.83%\n",
      "| Elapsed time : 0:21:54\n",
      "\n",
      "=> Training Epoch #23, LR=0.1000\n",
      "| Epoch [ 23/200] Iter[391/391]\t\tLoss: 0.4980 Acc@1: 83.816%\n",
      "| Validation Epoch #23\t\t\tLoss: 0.7285 Acc@1: 80.15%\n",
      "| Elapsed time : 0:22:52\n",
      "\n",
      "=> Training Epoch #24, LR=0.1000\n",
      "| Epoch [ 24/200] Iter[391/391]\t\tLoss: 0.4900 Acc@1: 84.086%\n",
      "| Validation Epoch #24\t\t\tLoss: 0.6779 Acc@1: 80.99%\n",
      "| Saving Best model...\t\t\tTop1 = 80.99%\n",
      "| Elapsed time : 0:23:50\n",
      "\n",
      "=> Training Epoch #25, LR=0.1000\n",
      "| Epoch [ 25/200] Iter[391/391]\t\tLoss: 0.5720 Acc@1: 84.074%\n",
      "| Validation Epoch #25\t\t\tLoss: 0.5354 Acc@1: 80.72%\n",
      "| Elapsed time : 0:24:48\n",
      "\n",
      "=> Training Epoch #26, LR=0.1000\n",
      "| Epoch [ 26/200] Iter[391/391]\t\tLoss: 0.5983 Acc@1: 84.030%\n",
      "| Validation Epoch #26\t\t\tLoss: 0.5560 Acc@1: 81.58%\n",
      "| Saving Best model...\t\t\tTop1 = 81.58%\n",
      "| Elapsed time : 0:25:47\n",
      "\n",
      "=> Training Epoch #27, LR=0.1000\n",
      "| Epoch [ 27/200] Iter[391/391]\t\tLoss: 0.5677 Acc@1: 84.402%\n",
      "| Validation Epoch #27\t\t\tLoss: 0.5492 Acc@1: 81.73%\n",
      "| Saving Best model...\t\t\tTop1 = 81.73%\n",
      "| Elapsed time : 0:26:46\n",
      "\n",
      "=> Training Epoch #28, LR=0.1000\n",
      "| Epoch [ 28/200] Iter[391/391]\t\tLoss: 0.4621 Acc@1: 84.186%\n",
      "| Validation Epoch #28\t\t\tLoss: 0.5185 Acc@1: 81.67%\n",
      "| Elapsed time : 0:27:45\n",
      "\n",
      "=> Training Epoch #29, LR=0.1000\n",
      "| Epoch [ 29/200] Iter[391/391]\t\tLoss: 0.4298 Acc@1: 84.510%\n",
      "| Validation Epoch #29\t\t\tLoss: 0.8288 Acc@1: 79.58%\n",
      "| Elapsed time : 0:28:43\n",
      "\n",
      "=> Training Epoch #30, LR=0.1000\n",
      "| Epoch [ 30/200] Iter[391/391]\t\tLoss: 0.4617 Acc@1: 84.590%\n",
      "| Validation Epoch #30\t\t\tLoss: 0.4981 Acc@1: 84.02%\n",
      "| Saving Best model...\t\t\tTop1 = 84.02%\n",
      "| Elapsed time : 0:29:42\n",
      "\n",
      "=> Training Epoch #31, LR=0.1000\n",
      "| Epoch [ 31/200] Iter[391/391]\t\tLoss: 0.4153 Acc@1: 84.428%\n",
      "| Validation Epoch #31\t\t\tLoss: 0.5088 Acc@1: 81.64%\n",
      "| Elapsed time : 0:30:40\n",
      "\n",
      "=> Training Epoch #32, LR=0.1000\n",
      "| Epoch [ 32/200] Iter[391/391]\t\tLoss: 0.4935 Acc@1: 84.614%\n",
      "| Validation Epoch #32\t\t\tLoss: 0.7049 Acc@1: 77.58%\n",
      "| Elapsed time : 0:31:40\n",
      "\n",
      "=> Training Epoch #33, LR=0.1000\n",
      "| Epoch [ 33/200] Iter[391/391]\t\tLoss: 0.4915 Acc@1: 84.876%\n",
      "| Validation Epoch #33\t\t\tLoss: 0.5492 Acc@1: 80.47%\n",
      "| Elapsed time : 0:32:39\n",
      "\n",
      "=> Training Epoch #34, LR=0.1000\n",
      "| Epoch [ 34/200] Iter[391/391]\t\tLoss: 0.5089 Acc@1: 84.586%\n",
      "| Validation Epoch #34\t\t\tLoss: 0.8322 Acc@1: 76.35%\n",
      "| Elapsed time : 0:33:38\n",
      "\n",
      "=> Training Epoch #35, LR=0.1000\n",
      "| Epoch [ 35/200] Iter[391/391]\t\tLoss: 0.5388 Acc@1: 84.968%\n",
      "| Validation Epoch #35\t\t\tLoss: 0.4283 Acc@1: 82.38%\n",
      "| Elapsed time : 0:34:37\n",
      "\n",
      "=> Training Epoch #36, LR=0.1000\n",
      "| Epoch [ 36/200] Iter[391/391]\t\tLoss: 0.3293 Acc@1: 84.840%\n",
      "| Validation Epoch #36\t\t\tLoss: 0.7852 Acc@1: 80.31%\n",
      "| Elapsed time : 0:35:36\n",
      "\n",
      "=> Training Epoch #37, LR=0.1000\n",
      "| Epoch [ 37/200] Iter[391/391]\t\tLoss: 0.3628 Acc@1: 85.004%\n",
      "| Validation Epoch #37\t\t\tLoss: 0.4288 Acc@1: 83.79%\n",
      "| Elapsed time : 0:36:36\n",
      "\n",
      "=> Training Epoch #38, LR=0.1000\n",
      "| Epoch [ 38/200] Iter[391/391]\t\tLoss: 0.5049 Acc@1: 84.906%\n",
      "| Validation Epoch #38\t\t\tLoss: 0.5646 Acc@1: 82.83%\n",
      "| Elapsed time : 0:37:35\n",
      "\n",
      "=> Training Epoch #39, LR=0.1000\n",
      "| Epoch [ 39/200] Iter[391/391]\t\tLoss: 0.2823 Acc@1: 84.832%\n",
      "| Validation Epoch #39\t\t\tLoss: 0.7698 Acc@1: 80.61%\n",
      "| Elapsed time : 0:38:33\n",
      "\n",
      "=> Training Epoch #40, LR=0.1000\n",
      "| Epoch [ 40/200] Iter[391/391]\t\tLoss: 0.4208 Acc@1: 85.182%\n",
      "| Validation Epoch #40\t\t\tLoss: 0.7175 Acc@1: 79.34%\n",
      "| Elapsed time : 0:39:32\n",
      "\n",
      "=> Training Epoch #41, LR=0.1000\n",
      "| Epoch [ 41/200] Iter[391/391]\t\tLoss: 0.3557 Acc@1: 85.206%\n",
      "| Validation Epoch #41\t\t\tLoss: 0.5732 Acc@1: 81.66%\n",
      "| Elapsed time : 0:40:32\n",
      "\n",
      "=> Training Epoch #42, LR=0.1000\n",
      "| Epoch [ 42/200] Iter[391/391]\t\tLoss: 0.5556 Acc@1: 85.112%\n",
      "| Validation Epoch #42\t\t\tLoss: 0.5199 Acc@1: 80.72%\n",
      "| Elapsed time : 0:41:31\n",
      "\n",
      "=> Training Epoch #43, LR=0.1000\n",
      "| Epoch [ 43/200] Iter[391/391]\t\tLoss: 0.3308 Acc@1: 85.300%\n",
      "| Validation Epoch #43\t\t\tLoss: 0.4705 Acc@1: 82.16%\n",
      "| Elapsed time : 0:42:30\n",
      "\n",
      "=> Training Epoch #44, LR=0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 44/200] Iter[391/391]\t\tLoss: 0.3948 Acc@1: 85.552%\n",
      "| Validation Epoch #44\t\t\tLoss: 0.5660 Acc@1: 81.10%\n",
      "| Elapsed time : 0:43:29\n",
      "\n",
      "=> Training Epoch #45, LR=0.1000\n",
      "| Epoch [ 45/200] Iter[391/391]\t\tLoss: 0.3570 Acc@1: 85.292%\n",
      "| Validation Epoch #45\t\t\tLoss: 0.7185 Acc@1: 77.11%\n",
      "| Elapsed time : 0:44:28\n",
      "\n",
      "=> Training Epoch #46, LR=0.1000\n",
      "| Epoch [ 46/200] Iter[391/391]\t\tLoss: 0.5731 Acc@1: 85.356%\n",
      "| Validation Epoch #46\t\t\tLoss: 0.4151 Acc@1: 80.61%\n",
      "| Elapsed time : 0:45:28\n",
      "\n",
      "=> Training Epoch #47, LR=0.1000\n",
      "| Epoch [ 47/200] Iter[391/391]\t\tLoss: 0.5026 Acc@1: 85.438%\n",
      "| Validation Epoch #47\t\t\tLoss: 0.3826 Acc@1: 79.84%\n",
      "| Elapsed time : 0:46:26\n",
      "\n",
      "=> Training Epoch #48, LR=0.1000\n",
      "| Epoch [ 48/200] Iter[391/391]\t\tLoss: 0.3908 Acc@1: 85.348%\n",
      "| Validation Epoch #48\t\t\tLoss: 0.6840 Acc@1: 78.21%\n",
      "| Elapsed time : 0:47:24\n",
      "\n",
      "=> Training Epoch #49, LR=0.1000\n",
      "| Epoch [ 49/200] Iter[391/391]\t\tLoss: 0.4718 Acc@1: 85.396%\n",
      "| Validation Epoch #49\t\t\tLoss: 0.3552 Acc@1: 84.20%\n",
      "| Saving Best model...\t\t\tTop1 = 84.20%\n",
      "| Elapsed time : 0:48:22\n",
      "\n",
      "=> Training Epoch #50, LR=0.1000\n",
      "| Epoch [ 50/200] Iter[391/391]\t\tLoss: 0.2975 Acc@1: 85.620%\n",
      "| Validation Epoch #50\t\t\tLoss: 0.7526 Acc@1: 81.69%\n",
      "| Elapsed time : 0:49:20\n",
      "\n",
      "=> Training Epoch #51, LR=0.1000\n",
      "| Epoch [ 51/200] Iter[391/391]\t\tLoss: 0.4892 Acc@1: 85.566%\n",
      "| Validation Epoch #51\t\t\tLoss: 0.5273 Acc@1: 83.50%\n",
      "| Elapsed time : 0:50:18\n",
      "\n",
      "=> Training Epoch #52, LR=0.1000\n",
      "| Epoch [ 52/200] Iter[391/391]\t\tLoss: 0.2427 Acc@1: 85.416%\n",
      "| Validation Epoch #52\t\t\tLoss: 0.3928 Acc@1: 84.71%\n",
      "| Saving Best model...\t\t\tTop1 = 84.71%\n",
      "| Elapsed time : 0:51:17\n",
      "\n",
      "=> Training Epoch #53, LR=0.1000\n",
      "| Epoch [ 53/200] Iter[391/391]\t\tLoss: 0.3609 Acc@1: 85.540%\n",
      "| Validation Epoch #53\t\t\tLoss: 0.6936 Acc@1: 78.70%\n",
      "| Elapsed time : 0:52:16\n",
      "\n",
      "=> Training Epoch #54, LR=0.1000\n",
      "| Epoch [ 54/200] Iter[391/391]\t\tLoss: 0.3968 Acc@1: 85.806%\n",
      "| Validation Epoch #54\t\t\tLoss: 0.5457 Acc@1: 83.23%\n",
      "| Elapsed time : 0:53:14\n",
      "\n",
      "=> Training Epoch #55, LR=0.1000\n",
      "| Epoch [ 55/200] Iter[391/391]\t\tLoss: 0.6015 Acc@1: 85.788%\n",
      "| Validation Epoch #55\t\t\tLoss: 0.6731 Acc@1: 79.32%\n",
      "| Elapsed time : 0:54:12\n",
      "\n",
      "=> Training Epoch #56, LR=0.1000\n",
      "| Epoch [ 56/200] Iter[391/391]\t\tLoss: 0.5279 Acc@1: 85.666%\n",
      "| Validation Epoch #56\t\t\tLoss: 0.6414 Acc@1: 81.44%\n",
      "| Elapsed time : 0:55:11\n",
      "\n",
      "=> Training Epoch #57, LR=0.1000\n",
      "| Epoch [ 57/200] Iter[391/391]\t\tLoss: 0.4133 Acc@1: 85.580%\n",
      "| Validation Epoch #57\t\t\tLoss: 0.4214 Acc@1: 81.36%\n",
      "| Elapsed time : 0:56:10\n",
      "\n",
      "=> Training Epoch #58, LR=0.1000\n",
      "| Epoch [ 58/200] Iter[391/391]\t\tLoss: 0.5031 Acc@1: 85.556%\n",
      "| Validation Epoch #58\t\t\tLoss: 0.5653 Acc@1: 80.22%\n",
      "| Elapsed time : 0:57:08\n",
      "\n",
      "=> Training Epoch #59, LR=0.1000\n",
      "| Epoch [ 59/200] Iter[391/391]\t\tLoss: 0.4913 Acc@1: 85.904%\n",
      "| Validation Epoch #59\t\t\tLoss: 0.4790 Acc@1: 81.02%\n",
      "| Elapsed time : 0:58:08\n",
      "\n",
      "=> Training Epoch #60, LR=0.1000\n",
      "| Epoch [ 60/200] Iter[391/391]\t\tLoss: 0.5470 Acc@1: 85.976%\n",
      "| Validation Epoch #60\t\t\tLoss: 0.4987 Acc@1: 81.56%\n",
      "| Elapsed time : 0:59:07\n",
      "\n",
      "=> Training Epoch #61, LR=0.0200\n",
      "| Epoch [ 61/200] Iter[391/391]\t\tLoss: 0.2382 Acc@1: 91.350%\n",
      "| Validation Epoch #61\t\t\tLoss: 0.1918 Acc@1: 90.85%\n",
      "| Saving Best model...\t\t\tTop1 = 90.85%\n",
      "| Elapsed time : 1:00:07\n",
      "\n",
      "=> Training Epoch #62, LR=0.0200\n",
      "| Epoch [ 62/200] Iter[391/391]\t\tLoss: 0.2335 Acc@1: 92.778%\n",
      "| Validation Epoch #62\t\t\tLoss: 0.2238 Acc@1: 90.52%\n",
      "| Elapsed time : 1:01:06\n",
      "\n",
      "=> Training Epoch #63, LR=0.0200\n",
      "| Epoch [ 63/200] Iter[391/391]\t\tLoss: 0.1988 Acc@1: 93.244%\n",
      "| Validation Epoch #63\t\t\tLoss: 0.1517 Acc@1: 91.76%\n",
      "| Saving Best model...\t\t\tTop1 = 91.76%\n",
      "| Elapsed time : 1:02:05\n",
      "\n",
      "=> Training Epoch #64, LR=0.0200\n",
      "| Epoch [ 64/200] Iter[391/391]\t\tLoss: 0.3050 Acc@1: 93.698%\n",
      "| Validation Epoch #64\t\t\tLoss: 0.2715 Acc@1: 90.55%\n",
      "| Elapsed time : 1:03:04\n",
      "\n",
      "=> Training Epoch #65, LR=0.0200\n",
      "| Epoch [ 65/200] Iter[391/391]\t\tLoss: 0.2495 Acc@1: 93.796%\n",
      "| Validation Epoch #65\t\t\tLoss: 0.2212 Acc@1: 91.43%\n",
      "| Elapsed time : 1:04:03\n",
      "\n",
      "=> Training Epoch #66, LR=0.0200\n",
      "| Epoch [ 66/200] Iter[391/391]\t\tLoss: 0.1725 Acc@1: 93.982%\n",
      "| Validation Epoch #66\t\t\tLoss: 0.2603 Acc@1: 91.02%\n",
      "| Elapsed time : 1:05:02\n",
      "\n",
      "=> Training Epoch #67, LR=0.0200\n",
      "| Epoch [ 67/200] Iter[391/391]\t\tLoss: 0.2120 Acc@1: 94.020%\n",
      "| Validation Epoch #67\t\t\tLoss: 0.2447 Acc@1: 90.19%\n",
      "| Elapsed time : 1:06:00\n",
      "\n",
      "=> Training Epoch #68, LR=0.0200\n",
      "| Epoch [ 68/200] Iter[391/391]\t\tLoss: 0.2515 Acc@1: 94.010%\n",
      "| Validation Epoch #68\t\t\tLoss: 0.3665 Acc@1: 89.03%\n",
      "| Elapsed time : 1:07:00\n",
      "\n",
      "=> Training Epoch #69, LR=0.0200\n",
      "| Epoch [ 69/200] Iter[391/391]\t\tLoss: 0.2509 Acc@1: 93.936%\n",
      "| Validation Epoch #69\t\t\tLoss: 0.2313 Acc@1: 90.05%\n",
      "| Elapsed time : 1:07:58\n",
      "\n",
      "=> Training Epoch #70, LR=0.0200\n",
      "| Epoch [ 70/200] Iter[391/391]\t\tLoss: 0.1361 Acc@1: 94.156%\n",
      "| Validation Epoch #70\t\t\tLoss: 0.2659 Acc@1: 90.67%\n",
      "| Elapsed time : 1:08:57\n",
      "\n",
      "=> Training Epoch #71, LR=0.0200\n",
      "| Epoch [ 71/200] Iter[391/391]\t\tLoss: 0.1326 Acc@1: 94.134%\n",
      "| Validation Epoch #71\t\t\tLoss: 0.3252 Acc@1: 89.55%\n",
      "| Elapsed time : 1:09:55\n",
      "\n",
      "=> Training Epoch #72, LR=0.0200\n",
      "| Epoch [ 72/200] Iter[391/391]\t\tLoss: 0.1104 Acc@1: 94.200%\n",
      "| Validation Epoch #72\t\t\tLoss: 0.2852 Acc@1: 90.21%\n",
      "| Elapsed time : 1:10:54\n",
      "\n",
      "=> Training Epoch #73, LR=0.0200\n",
      "| Epoch [ 73/200] Iter[391/391]\t\tLoss: 0.1527 Acc@1: 93.952%\n",
      "| Validation Epoch #73\t\t\tLoss: 0.3715 Acc@1: 90.55%\n",
      "| Elapsed time : 1:11:53\n",
      "\n",
      "=> Training Epoch #74, LR=0.0200\n",
      "| Epoch [ 74/200] Iter[391/391]\t\tLoss: 0.1313 Acc@1: 93.892%\n",
      "| Validation Epoch #74\t\t\tLoss: 0.3750 Acc@1: 89.64%\n",
      "| Elapsed time : 1:12:52\n",
      "\n",
      "=> Training Epoch #75, LR=0.0200\n",
      "| Epoch [ 75/200] Iter[391/391]\t\tLoss: 0.1136 Acc@1: 94.100%\n",
      "| Validation Epoch #75\t\t\tLoss: 0.3374 Acc@1: 90.68%\n",
      "| Elapsed time : 1:13:51\n",
      "\n",
      "=> Training Epoch #76, LR=0.0200\n",
      "| Epoch [ 76/200] Iter[391/391]\t\tLoss: 0.1627 Acc@1: 93.782%\n",
      "| Validation Epoch #76\t\t\tLoss: 0.3170 Acc@1: 89.21%\n",
      "| Elapsed time : 1:14:49\n",
      "\n",
      "=> Training Epoch #77, LR=0.0200\n",
      "| Epoch [ 77/200] Iter[391/391]\t\tLoss: 0.1269 Acc@1: 94.152%\n",
      "| Validation Epoch #77\t\t\tLoss: 0.4052 Acc@1: 90.24%\n",
      "| Elapsed time : 1:15:47\n",
      "\n",
      "=> Training Epoch #78, LR=0.0200\n",
      "| Epoch [ 78/200] Iter[391/391]\t\tLoss: 0.1749 Acc@1: 94.100%\n",
      "| Validation Epoch #78\t\t\tLoss: 0.3416 Acc@1: 88.41%\n",
      "| Elapsed time : 1:16:46\n",
      "\n",
      "=> Training Epoch #79, LR=0.0200\n",
      "| Epoch [ 79/200] Iter[391/391]\t\tLoss: 0.2055 Acc@1: 93.942%\n",
      "| Validation Epoch #79\t\t\tLoss: 0.2615 Acc@1: 89.96%\n",
      "| Elapsed time : 1:17:45\n",
      "\n",
      "=> Training Epoch #80, LR=0.0200\n",
      "| Epoch [ 80/200] Iter[391/391]\t\tLoss: 0.2746 Acc@1: 94.142%\n",
      "| Validation Epoch #80\t\t\tLoss: 0.3813 Acc@1: 89.66%\n",
      "| Elapsed time : 1:18:43\n",
      "\n",
      "=> Training Epoch #81, LR=0.0200\n",
      "| Epoch [ 81/200] Iter[391/391]\t\tLoss: 0.1666 Acc@1: 93.964%\n",
      "| Validation Epoch #81\t\t\tLoss: 0.2764 Acc@1: 90.63%\n",
      "| Elapsed time : 1:19:42\n",
      "\n",
      "=> Training Epoch #82, LR=0.0200\n",
      "| Epoch [ 82/200] Iter[391/391]\t\tLoss: 0.2087 Acc@1: 94.006%\n",
      "| Validation Epoch #82\t\t\tLoss: 0.3145 Acc@1: 89.45%\n",
      "| Elapsed time : 1:20:41\n",
      "\n",
      "=> Training Epoch #83, LR=0.0200\n",
      "| Epoch [ 83/200] Iter[391/391]\t\tLoss: 0.3053 Acc@1: 94.106%\n",
      "| Validation Epoch #83\t\t\tLoss: 0.4124 Acc@1: 89.35%\n",
      "| Elapsed time : 1:21:40\n",
      "\n",
      "=> Training Epoch #84, LR=0.0200\n",
      "| Epoch [ 84/200] Iter[391/391]\t\tLoss: 0.2817 Acc@1: 93.964%\n",
      "| Validation Epoch #84\t\t\tLoss: 0.3051 Acc@1: 89.81%\n",
      "| Elapsed time : 1:22:38\n",
      "\n",
      "=> Training Epoch #85, LR=0.0200\n",
      "| Epoch [ 85/200] Iter[391/391]\t\tLoss: 0.1898 Acc@1: 94.180%\n",
      "| Validation Epoch #85\t\t\tLoss: 0.2116 Acc@1: 89.56%\n",
      "| Elapsed time : 1:23:37\n",
      "\n",
      "=> Training Epoch #86, LR=0.0200\n",
      "| Epoch [ 86/200] Iter[391/391]\t\tLoss: 0.2176 Acc@1: 94.046%\n",
      "| Validation Epoch #86\t\t\tLoss: 0.2958 Acc@1: 90.78%\n",
      "| Elapsed time : 1:24:37\n",
      "\n",
      "=> Training Epoch #87, LR=0.0200\n",
      "| Epoch [ 87/200] Iter[391/391]\t\tLoss: 0.1842 Acc@1: 93.914%\n",
      "| Validation Epoch #87\t\t\tLoss: 0.2923 Acc@1: 88.68%\n",
      "| Elapsed time : 1:25:36\n",
      "\n",
      "=> Training Epoch #88, LR=0.0200\n",
      "| Epoch [ 88/200] Iter[391/391]\t\tLoss: 0.2250 Acc@1: 94.058%\n",
      "| Validation Epoch #88\t\t\tLoss: 0.3697 Acc@1: 90.24%\n",
      "| Elapsed time : 1:26:35\n",
      "\n",
      "=> Training Epoch #89, LR=0.0200\n",
      "| Epoch [ 89/200] Iter[391/391]\t\tLoss: 0.2200 Acc@1: 94.082%\n",
      "| Validation Epoch #89\t\t\tLoss: 0.3694 Acc@1: 89.10%\n",
      "| Elapsed time : 1:27:34\n",
      "\n",
      "=> Training Epoch #90, LR=0.0200\n",
      "| Epoch [ 90/200] Iter[391/391]\t\tLoss: 0.1971 Acc@1: 94.086%\n",
      "| Validation Epoch #90\t\t\tLoss: 0.2257 Acc@1: 89.58%\n",
      "| Elapsed time : 1:28:33\n",
      "\n",
      "=> Training Epoch #91, LR=0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 91/200] Iter[391/391]\t\tLoss: 0.1241 Acc@1: 94.178%\n",
      "| Validation Epoch #91\t\t\tLoss: 0.2151 Acc@1: 88.74%\n",
      "| Elapsed time : 1:29:31\n",
      "\n",
      "=> Training Epoch #92, LR=0.0200\n",
      "| Epoch [ 92/200] Iter[391/391]\t\tLoss: 0.2712 Acc@1: 94.300%\n",
      "| Validation Epoch #92\t\t\tLoss: 0.3623 Acc@1: 90.44%\n",
      "| Elapsed time : 1:30:30\n",
      "\n",
      "=> Training Epoch #93, LR=0.0200\n",
      "| Epoch [ 93/200] Iter[391/391]\t\tLoss: 0.2832 Acc@1: 94.084%\n",
      "| Validation Epoch #93\t\t\tLoss: 0.2848 Acc@1: 89.10%\n",
      "| Elapsed time : 1:31:28\n",
      "\n",
      "=> Training Epoch #94, LR=0.0200\n",
      "| Epoch [ 94/200] Iter[391/391]\t\tLoss: 0.1976 Acc@1: 94.104%\n",
      "| Validation Epoch #94\t\t\tLoss: 0.3292 Acc@1: 88.90%\n",
      "| Elapsed time : 1:32:27\n",
      "\n",
      "=> Training Epoch #95, LR=0.0200\n",
      "| Epoch [ 95/200] Iter[391/391]\t\tLoss: 0.2950 Acc@1: 94.540%\n",
      "| Validation Epoch #95\t\t\tLoss: 0.3632 Acc@1: 89.18%\n",
      "| Elapsed time : 1:33:27\n",
      "\n",
      "=> Training Epoch #96, LR=0.0200\n",
      "| Epoch [ 96/200] Iter[391/391]\t\tLoss: 0.1884 Acc@1: 94.350%\n",
      "| Validation Epoch #96\t\t\tLoss: 0.3958 Acc@1: 88.59%\n",
      "| Elapsed time : 1:34:26\n",
      "\n",
      "=> Training Epoch #97, LR=0.0200\n",
      "| Epoch [ 97/200] Iter[391/391]\t\tLoss: 0.2314 Acc@1: 94.026%\n",
      "| Validation Epoch #97\t\t\tLoss: 0.3085 Acc@1: 90.85%\n",
      "| Elapsed time : 1:35:26\n",
      "\n",
      "=> Training Epoch #98, LR=0.0200\n",
      "| Epoch [ 98/200] Iter[391/391]\t\tLoss: 0.1695 Acc@1: 94.176%\n",
      "| Validation Epoch #98\t\t\tLoss: 0.2393 Acc@1: 88.81%\n",
      "| Elapsed time : 1:36:25\n",
      "\n",
      "=> Training Epoch #99, LR=0.0200\n",
      "| Epoch [ 99/200] Iter[391/391]\t\tLoss: 0.2446 Acc@1: 94.334%\n",
      "| Validation Epoch #99\t\t\tLoss: 0.2755 Acc@1: 89.83%\n",
      "| Elapsed time : 1:37:25\n",
      "\n",
      "=> Training Epoch #100, LR=0.0200\n",
      "| Epoch [100/200] Iter[391/391]\t\tLoss: 0.1306 Acc@1: 94.354%\n",
      "| Validation Epoch #100\t\t\tLoss: 0.2240 Acc@1: 88.81%\n",
      "| Elapsed time : 1:38:25\n",
      "\n",
      "=> Training Epoch #101, LR=0.0200\n",
      "| Epoch [101/200] Iter[391/391]\t\tLoss: 0.1192 Acc@1: 94.584%\n",
      "| Validation Epoch #101\t\t\tLoss: 0.4334 Acc@1: 88.50%\n",
      "| Elapsed time : 1:39:25\n",
      "\n",
      "=> Training Epoch #102, LR=0.0200\n",
      "| Epoch [102/200] Iter[391/391]\t\tLoss: 0.1658 Acc@1: 94.352%\n",
      "| Validation Epoch #102\t\t\tLoss: 0.2038 Acc@1: 90.25%\n",
      "| Elapsed time : 1:40:24\n",
      "\n",
      "=> Training Epoch #103, LR=0.0200\n",
      "| Epoch [103/200] Iter[391/391]\t\tLoss: 0.0952 Acc@1: 94.560%\n",
      "| Validation Epoch #103\t\t\tLoss: 0.2750 Acc@1: 88.64%\n",
      "| Elapsed time : 1:41:24\n",
      "\n",
      "=> Training Epoch #104, LR=0.0200\n",
      "| Epoch [104/200] Iter[391/391]\t\tLoss: 0.0897 Acc@1: 94.668%\n",
      "| Validation Epoch #104\t\t\tLoss: 0.3204 Acc@1: 89.66%\n",
      "| Elapsed time : 1:42:23\n",
      "\n",
      "=> Training Epoch #105, LR=0.0200\n",
      "| Epoch [105/200] Iter[391/391]\t\tLoss: 0.1310 Acc@1: 94.478%\n",
      "| Validation Epoch #105\t\t\tLoss: 0.3354 Acc@1: 90.08%\n",
      "| Elapsed time : 1:43:23\n",
      "\n",
      "=> Training Epoch #106, LR=0.0200\n",
      "| Epoch [106/200] Iter[391/391]\t\tLoss: 0.2494 Acc@1: 94.676%\n",
      "| Validation Epoch #106\t\t\tLoss: 0.4231 Acc@1: 89.29%\n",
      "| Elapsed time : 1:44:23\n",
      "\n",
      "=> Training Epoch #107, LR=0.0200\n",
      "| Epoch [107/200] Iter[391/391]\t\tLoss: 0.4091 Acc@1: 94.450%\n",
      "| Validation Epoch #107\t\t\tLoss: 0.2951 Acc@1: 90.30%\n",
      "| Elapsed time : 1:45:22\n",
      "\n",
      "=> Training Epoch #108, LR=0.0200\n",
      "| Epoch [108/200] Iter[391/391]\t\tLoss: 0.1465 Acc@1: 94.504%\n",
      "| Validation Epoch #108\t\t\tLoss: 0.5458 Acc@1: 89.16%\n",
      "| Elapsed time : 1:46:22\n",
      "\n",
      "=> Training Epoch #109, LR=0.0200\n",
      "| Epoch [109/200] Iter[391/391]\t\tLoss: 0.1689 Acc@1: 94.612%\n",
      "| Validation Epoch #109\t\t\tLoss: 0.2211 Acc@1: 89.74%\n",
      "| Elapsed time : 1:47:21\n",
      "\n",
      "=> Training Epoch #110, LR=0.0200\n",
      "| Epoch [110/200] Iter[391/391]\t\tLoss: 0.2839 Acc@1: 94.544%\n",
      "| Validation Epoch #110\t\t\tLoss: 0.3682 Acc@1: 88.62%\n",
      "| Elapsed time : 1:48:20\n",
      "\n",
      "=> Training Epoch #111, LR=0.0200\n",
      "| Epoch [111/200] Iter[391/391]\t\tLoss: 0.1628 Acc@1: 94.640%\n",
      "| Validation Epoch #111\t\t\tLoss: 0.3573 Acc@1: 89.88%\n",
      "| Elapsed time : 1:49:20\n",
      "\n",
      "=> Training Epoch #112, LR=0.0200\n",
      "| Epoch [112/200] Iter[391/391]\t\tLoss: 0.1624 Acc@1: 94.712%\n",
      "| Validation Epoch #112\t\t\tLoss: 0.2682 Acc@1: 90.50%\n",
      "| Elapsed time : 1:50:19\n",
      "\n",
      "=> Training Epoch #113, LR=0.0200\n",
      "| Epoch [113/200] Iter[391/391]\t\tLoss: 0.1017 Acc@1: 94.544%\n",
      "| Validation Epoch #113\t\t\tLoss: 0.1977 Acc@1: 90.56%\n",
      "| Elapsed time : 1:51:17\n",
      "\n",
      "=> Training Epoch #114, LR=0.0200\n",
      "| Epoch [114/200] Iter[391/391]\t\tLoss: 0.3339 Acc@1: 94.524%\n",
      "| Validation Epoch #114\t\t\tLoss: 0.2689 Acc@1: 90.05%\n",
      "| Elapsed time : 1:52:15\n",
      "\n",
      "=> Training Epoch #115, LR=0.0200\n",
      "| Epoch [115/200] Iter[391/391]\t\tLoss: 0.1449 Acc@1: 94.664%\n",
      "| Validation Epoch #115\t\t\tLoss: 0.3835 Acc@1: 88.97%\n",
      "| Elapsed time : 1:53:13\n",
      "\n",
      "=> Training Epoch #116, LR=0.0200\n",
      "| Epoch [116/200] Iter[391/391]\t\tLoss: 0.1490 Acc@1: 94.514%\n",
      "| Validation Epoch #116\t\t\tLoss: 0.4504 Acc@1: 87.81%\n",
      "| Elapsed time : 1:54:12\n",
      "\n",
      "=> Training Epoch #117, LR=0.0200\n",
      "| Epoch [117/200] Iter[391/391]\t\tLoss: 0.2415 Acc@1: 94.788%\n",
      "| Validation Epoch #117\t\t\tLoss: 0.3161 Acc@1: 90.49%\n",
      "| Elapsed time : 1:55:10\n",
      "\n",
      "=> Training Epoch #118, LR=0.0200\n",
      "| Epoch [118/200] Iter[391/391]\t\tLoss: 0.1039 Acc@1: 94.542%\n",
      "| Validation Epoch #118\t\t\tLoss: 0.2418 Acc@1: 89.52%\n",
      "| Elapsed time : 1:56:09\n",
      "\n",
      "=> Training Epoch #119, LR=0.0200\n",
      "| Epoch [119/200] Iter[391/391]\t\tLoss: 0.3078 Acc@1: 94.794%\n",
      "| Validation Epoch #119\t\t\tLoss: 0.3766 Acc@1: 88.29%\n",
      "| Elapsed time : 1:57:09\n",
      "\n",
      "=> Training Epoch #120, LR=0.0200\n",
      "| Epoch [120/200] Iter[391/391]\t\tLoss: 0.0637 Acc@1: 95.014%\n",
      "| Validation Epoch #120\t\t\tLoss: 0.2067 Acc@1: 90.35%\n",
      "| Elapsed time : 1:58:08\n",
      "\n",
      "=> Training Epoch #121, LR=0.0040\n",
      "| Epoch [121/200] Iter[391/391]\t\tLoss: 0.0548 Acc@1: 97.412%\n",
      "| Validation Epoch #121\t\t\tLoss: 0.2320 Acc@1: 92.87%\n",
      "| Saving Best model...\t\t\tTop1 = 92.87%\n",
      "| Elapsed time : 1:59:07\n",
      "\n",
      "=> Training Epoch #122, LR=0.0040\n",
      "| Epoch [122/200] Iter[391/391]\t\tLoss: 0.0508 Acc@1: 98.150%\n",
      "| Validation Epoch #122\t\t\tLoss: 0.2243 Acc@1: 92.64%\n",
      "| Elapsed time : 2:00:07\n",
      "\n",
      "=> Training Epoch #123, LR=0.0040\n",
      "| Epoch [123/200] Iter[391/391]\t\tLoss: 0.0556 Acc@1: 98.414%\n",
      "| Validation Epoch #123\t\t\tLoss: 0.1995 Acc@1: 93.22%\n",
      "| Saving Best model...\t\t\tTop1 = 93.22%\n",
      "| Elapsed time : 2:01:06\n",
      "\n",
      "=> Training Epoch #124, LR=0.0040\n",
      "| Epoch [124/200] Iter[391/391]\t\tLoss: 0.0485 Acc@1: 98.618%\n",
      "| Validation Epoch #124\t\t\tLoss: 0.2495 Acc@1: 92.90%\n",
      "| Elapsed time : 2:02:05\n",
      "\n",
      "=> Training Epoch #125, LR=0.0040\n",
      "| Epoch [125/200] Iter[391/391]\t\tLoss: 0.0317 Acc@1: 98.702%\n",
      "| Validation Epoch #125\t\t\tLoss: 0.1836 Acc@1: 93.32%\n",
      "| Saving Best model...\t\t\tTop1 = 93.32%\n",
      "| Elapsed time : 2:03:05\n",
      "\n",
      "=> Training Epoch #126, LR=0.0040\n",
      "| Epoch [126/200] Iter[391/391]\t\tLoss: 0.0547 Acc@1: 98.766%%\n",
      "| Validation Epoch #126\t\t\tLoss: 0.2394 Acc@1: 93.09%\n",
      "| Elapsed time : 2:04:04\n",
      "\n",
      "=> Training Epoch #127, LR=0.0040\n",
      "| Epoch [127/200] Iter[391/391]\t\tLoss: 0.0357 Acc@1: 98.792%%\n",
      "| Validation Epoch #127\t\t\tLoss: 0.2574 Acc@1: 93.22%\n",
      "| Elapsed time : 2:05:03\n",
      "\n",
      "=> Training Epoch #128, LR=0.0040\n",
      "| Epoch [128/200] Iter[391/391]\t\tLoss: 0.0073 Acc@1: 98.852%%\n",
      "| Validation Epoch #128\t\t\tLoss: 0.2450 Acc@1: 93.19%\n",
      "| Elapsed time : 2:06:01\n",
      "\n",
      "=> Training Epoch #129, LR=0.0040\n",
      "| Epoch [129/200] Iter[391/391]\t\tLoss: 0.0801 Acc@1: 98.908%\n",
      "| Validation Epoch #129\t\t\tLoss: 0.2696 Acc@1: 93.44%\n",
      "| Saving Best model...\t\t\tTop1 = 93.44%\n",
      "| Elapsed time : 2:07:00\n",
      "\n",
      "=> Training Epoch #130, LR=0.0040\n",
      "| Epoch [130/200] Iter[391/391]\t\tLoss: 0.0096 Acc@1: 99.024%\n",
      "| Validation Epoch #130\t\t\tLoss: 0.2676 Acc@1: 93.43%\n",
      "| Elapsed time : 2:07:58\n",
      "\n",
      "=> Training Epoch #131, LR=0.0040\n",
      "| Epoch [131/200] Iter[391/391]\t\tLoss: 0.0372 Acc@1: 98.986%\n",
      "| Validation Epoch #131\t\t\tLoss: 0.3179 Acc@1: 93.29%\n",
      "| Elapsed time : 2:08:56\n",
      "\n",
      "=> Training Epoch #132, LR=0.0040\n",
      "| Epoch [132/200] Iter[391/391]\t\tLoss: 0.0177 Acc@1: 99.120%%\n",
      "| Validation Epoch #132\t\t\tLoss: 0.2560 Acc@1: 93.07%\n",
      "| Elapsed time : 2:09:55\n",
      "\n",
      "=> Training Epoch #133, LR=0.0040\n",
      "| Epoch [133/200] Iter[391/391]\t\tLoss: 0.0136 Acc@1: 99.038%\n",
      "| Validation Epoch #133\t\t\tLoss: 0.2565 Acc@1: 93.03%\n",
      "| Elapsed time : 2:10:55\n",
      "\n",
      "=> Training Epoch #134, LR=0.0040\n",
      "| Epoch [134/200] Iter[391/391]\t\tLoss: 0.0308 Acc@1: 99.066%\n",
      "| Validation Epoch #134\t\t\tLoss: 0.2885 Acc@1: 92.89%\n",
      "| Elapsed time : 2:11:54\n",
      "\n",
      "=> Training Epoch #135, LR=0.0040\n",
      "| Epoch [135/200] Iter[391/391]\t\tLoss: 0.0144 Acc@1: 99.150%\n",
      "| Validation Epoch #135\t\t\tLoss: 0.2806 Acc@1: 92.74%\n",
      "| Elapsed time : 2:12:53\n",
      "\n",
      "=> Training Epoch #136, LR=0.0040\n",
      "| Epoch [136/200] Iter[391/391]\t\tLoss: 0.0442 Acc@1: 99.204%\n",
      "| Validation Epoch #136\t\t\tLoss: 0.2300 Acc@1: 92.98%\n",
      "| Elapsed time : 2:13:53\n",
      "\n",
      "=> Training Epoch #137, LR=0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [137/200] Iter[391/391]\t\tLoss: 0.0288 Acc@1: 99.150%\n",
      "| Validation Epoch #137\t\t\tLoss: 0.2670 Acc@1: 93.55%\n",
      "| Saving Best model...\t\t\tTop1 = 93.55%\n",
      "| Elapsed time : 2:14:52\n",
      "\n",
      "=> Training Epoch #138, LR=0.0040\n",
      "| Epoch [138/200] Iter[391/391]\t\tLoss: 0.0234 Acc@1: 99.162%\n",
      "| Validation Epoch #138\t\t\tLoss: 0.2807 Acc@1: 93.29%\n",
      "| Elapsed time : 2:15:51\n",
      "\n",
      "=> Training Epoch #139, LR=0.0040\n",
      "| Epoch [139/200] Iter[391/391]\t\tLoss: 0.0325 Acc@1: 99.160%\n",
      "| Validation Epoch #139\t\t\tLoss: 0.2683 Acc@1: 93.41%\n",
      "| Elapsed time : 2:16:48\n",
      "\n",
      "=> Training Epoch #140, LR=0.0040\n",
      "| Epoch [140/200] Iter[391/391]\t\tLoss: 0.0224 Acc@1: 99.202%\n",
      "| Validation Epoch #140\t\t\tLoss: 0.3384 Acc@1: 92.89%\n",
      "| Elapsed time : 2:17:46\n",
      "\n",
      "=> Training Epoch #141, LR=0.0040\n",
      "| Epoch [141/200] Iter[391/391]\t\tLoss: 0.1168 Acc@1: 99.190%%\n",
      "| Validation Epoch #141\t\t\tLoss: 0.2912 Acc@1: 93.01%\n",
      "| Elapsed time : 2:18:44\n",
      "\n",
      "=> Training Epoch #142, LR=0.0040\n",
      "| Epoch [142/200] Iter[391/391]\t\tLoss: 0.0389 Acc@1: 99.210%\n",
      "| Validation Epoch #142\t\t\tLoss: 0.3232 Acc@1: 92.96%\n",
      "| Elapsed time : 2:19:42\n",
      "\n",
      "=> Training Epoch #143, LR=0.0040\n",
      "| Epoch [143/200] Iter[391/391]\t\tLoss: 0.0173 Acc@1: 99.222%\n",
      "| Validation Epoch #143\t\t\tLoss: 0.2804 Acc@1: 93.30%\n",
      "| Elapsed time : 2:20:40\n",
      "\n",
      "=> Training Epoch #144, LR=0.0040\n",
      "| Epoch [144/200] Iter[391/391]\t\tLoss: 0.0225 Acc@1: 99.212%\n",
      "| Validation Epoch #144\t\t\tLoss: 0.3012 Acc@1: 92.89%\n",
      "| Elapsed time : 2:21:38\n",
      "\n",
      "=> Training Epoch #145, LR=0.0040\n",
      "| Epoch [145/200] Iter[391/391]\t\tLoss: 0.0080 Acc@1: 99.246%%\n",
      "| Validation Epoch #145\t\t\tLoss: 0.3465 Acc@1: 92.96%\n",
      "| Elapsed time : 2:22:36\n",
      "\n",
      "=> Training Epoch #146, LR=0.0040\n",
      "| Epoch [146/200] Iter[391/391]\t\tLoss: 0.0637 Acc@1: 99.172%\n",
      "| Validation Epoch #146\t\t\tLoss: 0.3388 Acc@1: 91.94%\n",
      "| Elapsed time : 2:23:35\n",
      "\n",
      "=> Training Epoch #147, LR=0.0040\n",
      "| Epoch [147/200] Iter[391/391]\t\tLoss: 0.0236 Acc@1: 99.192%\n",
      "| Validation Epoch #147\t\t\tLoss: 0.3393 Acc@1: 92.66%\n",
      "| Elapsed time : 2:24:35\n",
      "\n",
      "=> Training Epoch #148, LR=0.0040\n",
      "| Epoch [148/200] Iter[391/391]\t\tLoss: 0.0497 Acc@1: 99.224%%\n",
      "| Validation Epoch #148\t\t\tLoss: 0.3516 Acc@1: 92.57%\n",
      "| Elapsed time : 2:25:34\n",
      "\n",
      "=> Training Epoch #149, LR=0.0040\n",
      "| Epoch [149/200] Iter[391/391]\t\tLoss: 0.0262 Acc@1: 99.212%\n",
      "| Validation Epoch #149\t\t\tLoss: 0.3693 Acc@1: 91.94%\n",
      "| Elapsed time : 2:26:33\n",
      "\n",
      "=> Training Epoch #150, LR=0.0040\n",
      "| Epoch [150/200] Iter[391/391]\t\tLoss: 0.0281 Acc@1: 99.130%\n",
      "| Validation Epoch #150\t\t\tLoss: 0.3445 Acc@1: 92.68%\n",
      "| Elapsed time : 2:27:33\n",
      "\n",
      "=> Training Epoch #151, LR=0.0040\n",
      "| Epoch [151/200] Iter[391/391]\t\tLoss: 0.0228 Acc@1: 99.176%%\n",
      "| Validation Epoch #151\t\t\tLoss: 0.3460 Acc@1: 92.71%\n",
      "| Elapsed time : 2:28:33\n",
      "\n",
      "=> Training Epoch #152, LR=0.0040\n",
      "| Epoch [152/200] Iter[391/391]\t\tLoss: 0.0460 Acc@1: 99.258%%\n",
      "| Validation Epoch #152\t\t\tLoss: 0.3252 Acc@1: 92.02%\n",
      "| Elapsed time : 2:29:33\n",
      "\n",
      "=> Training Epoch #153, LR=0.0040\n",
      "| Epoch [153/200] Iter[391/391]\t\tLoss: 0.0173 Acc@1: 99.296%\n",
      "| Validation Epoch #153\t\t\tLoss: 0.4013 Acc@1: 92.38%\n",
      "| Elapsed time : 2:30:32\n",
      "\n",
      "=> Training Epoch #154, LR=0.0040\n",
      "| Epoch [154/200] Iter[391/391]\t\tLoss: 0.0425 Acc@1: 99.194%\n",
      "| Validation Epoch #154\t\t\tLoss: 0.3220 Acc@1: 91.87%\n",
      "| Elapsed time : 2:31:31\n",
      "\n",
      "=> Training Epoch #155, LR=0.0040\n",
      "| Epoch [155/200] Iter[391/391]\t\tLoss: 0.0775 Acc@1: 99.218%\n",
      "| Validation Epoch #155\t\t\tLoss: 0.3193 Acc@1: 92.30%\n",
      "| Elapsed time : 2:32:29\n",
      "\n",
      "=> Training Epoch #156, LR=0.0040\n",
      "| Epoch [156/200] Iter[391/391]\t\tLoss: 0.0365 Acc@1: 99.246%%\n",
      "| Validation Epoch #156\t\t\tLoss: 0.2790 Acc@1: 92.32%\n",
      "| Elapsed time : 2:33:28\n",
      "\n",
      "=> Training Epoch #157, LR=0.0040\n",
      "| Epoch [157/200] Iter[391/391]\t\tLoss: 0.0147 Acc@1: 99.238%\n",
      "| Validation Epoch #157\t\t\tLoss: 0.2978 Acc@1: 92.52%\n",
      "| Elapsed time : 2:34:26\n",
      "\n",
      "=> Training Epoch #158, LR=0.0040\n",
      "| Epoch [158/200] Iter[218/391]\t\tLoss: 0.0303 Acc@1: 99.165%%"
     ]
    }
   ],
   "source": [
    "##### TRAINING CELL #####\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Parameters settings\n",
    "depth = 40 ##can be 10, 16, 22, 28(default), 34, 40\n",
    "net_type = 'wide-resnet'\n",
    "lr = 0.1\n",
    "widen_factor = 2 #any numer, 10(default)\n",
    "dropout = 0.3\n",
    "dataset = 'cifar10'\n",
    "testOnly = False\n",
    "resume = False\n",
    "\n",
    "# Hyper Parameter settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "best_acc = 0\n",
    "\n",
    "# Data Uplaod\n",
    "print('\\n[Phase 1] : Data Preparation')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean[dataset], std[dataset]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean[dataset], std[dataset]),\n",
    "])\n",
    "\n",
    "if(dataset == 'cifar10'):\n",
    "    print(\"| Preparing CIFAR-10 dataset...\")\n",
    "    sys.stdout.write(\"| \")\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
    "    num_classes = 10\n",
    "elif(dataset == 'cifar100'):\n",
    "    print(\"| Preparing CIFAR-100 dataset...\")\n",
    "    sys.stdout.write(\"| \")\n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=False, transform=transform_test)\n",
    "    num_classes = 100\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define net\n",
    "net = Wide_ResNet(depth, widen_factor, dropout, num_classes)\n",
    "file_name = 'wide-resnet-'+str(depth)+'x'+str(widen_factor)\n",
    "\n",
    "\n",
    "# Test only option\n",
    "if (testOnly):\n",
    "    print('\\n[Test Phase] : Model setup')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        acc = 100.*correct/total\n",
    "        print(\"| Test Result\\tAcc@1: %.2f%%\" %(acc))\n",
    "\n",
    "    sys.exit(0)\n",
    "\n",
    "# Model\n",
    "print('\\n[Phase 2] : Model setup')\n",
    "if(resume):\n",
    "    # Load checkpoint\n",
    "    print('| Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('| Building net type [' + net_type + ']...')\n",
    "    net.apply(conv_init)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "    print('| Going fast AF with C U D A *o* !')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    net.training = True\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate(lr, epoch)))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)               # Forward Propagation\n",
    "        loss = criterion(outputs, targets)  # Loss\n",
    "        loss.backward()  # Backward Propagation\n",
    "        optimizer.step() # Optimizer update\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
    "                %(epoch, num_epochs, batch_idx+1,\n",
    "                    (len(trainset)//batch_size)+1, loss.item(), 100.*correct/total))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        # Save checkpoint when best model\n",
    "        acc = 100.*correct/total\n",
    "        print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
    "            state = {\n",
    "                    'net':net.module if use_cuda else net,\n",
    "                    'acc':acc,\n",
    "                    'epoch':epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            save_point = './checkpoint/'+dataset+os.sep\n",
    "            if not os.path.isdir(save_point):\n",
    "                os.mkdir(save_point)\n",
    "            torch.save(state, save_point+file_name+'.t7')\n",
    "            best_acc = acc\n",
    "\n",
    "print('\\n[Phase 3] : Training model')\n",
    "print('| Training Epochs = ' + str(num_epochs))\n",
    "print('| Initial Learning Rate = ' + str(lr))\n",
    "print('| Optimizer = ' + str(optim_type))\n",
    "\n",
    "elapsed_time = 0\n",
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    elapsed_time += epoch_time\n",
    "    print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
    "\n",
    "print('\\n[Phase 4] : Testing model')\n",
    "print('* Test results : Acc@1 = %.2f%%' %(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
