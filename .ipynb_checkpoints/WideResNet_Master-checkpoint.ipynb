{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Pytorch CIFAR configuration file ###############\n",
    "import math\n",
    "import functions.BinaryConnect as BC\n",
    "import functions.DataAugmentation as DA\n",
    "from functions.AutoAugment import AutoAugment, Cutout\n",
    "from models.WideResnet_HRank import Wide_ResNet_HRank, wide_basic\n",
    "\n",
    "start_epoch = 1\n",
    "num_epochs = 140\n",
    "batch_size = 128\n",
    "optim_type = 'SGD'\n",
    "\n",
    "mean = {\n",
    "    'cifar10': (0.4914, 0.4822, 0.4465),\n",
    "    'cifar100': (0.5071, 0.4867, 0.4408),\n",
    "}\n",
    "\n",
    "std = {\n",
    "    'cifar10': (0.2023, 0.1994, 0.2010),\n",
    "    'cifar100': (0.2675, 0.2565, 0.2761),\n",
    "}\n",
    "\n",
    "# Only for cifar-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if(epoch > 120):\n",
    "        optim_factor = 3\n",
    "    elif(epoch > 80):\n",
    "        optim_factor = 2\n",
    "    elif(epoch > 40):\n",
    "        optim_factor = 1\n",
    "\n",
    "    return init*math.pow(0.2, optim_factor)\n",
    "\n",
    "def get_hms(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "\n",
    "    return h, m, s\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAINING CELL #####\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Parameters settings\n",
    "depth = 40 ##can be 10, 16, 22, 28(default), 34, 40\n",
    "net_type = 'wide-resnet'\n",
    "lr = 0.1\n",
    "widen_factor = 2 #any numer, 10(default)\n",
    "dropout = 0.3\n",
    "dataset = 'cifar10'\n",
    "testOnly = False\n",
    "resume = False\n",
    "bc = False\n",
    "da = True\n",
    "# Hyper Parameter settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "best_acc = 0\n",
    "\n",
    "# Data Uplaod\n",
    "print('\\n[Phase 1] : Data Preparation')\n",
    "if da:\n",
    "    print(\\\"| Using Data Augmentation\")\n",
    "    to_da = DA.DataAugmentation(dataset,aa=True, cut=True)\n",
    "    if (dataset == 'cifar10'):\n",
    "        num_classes = 10\n",
    "    elif (dataset == 'cifar100'):\n",
    "        num_classes = 100\n",
    "    trainset_lenght,trainloader, testloader = to_da.load_data()\n",
    "else:\n",
    "    print(\\\"| Using no Data Augmentation\")\n",
    "    transform_train = transforms.Compose([,\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[dataset], std[dataset]),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean[dataset], std[dataset]),\n",
    "    ])\n",
    "    if(dataset == 'cifar10'):\n",
    "        print(\"| Preparing CIFAR-10 dataset...\")\n",
    "        sys.stdout.write(\"| \")\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform = transform_test)\n",
    "        trainset_length = len(trainset)\n",
    "        num_classes = 10\n",
    "    elif(dataset == 'cifar100'):\n",
    "        print(\"| Preparing CIFAR-100 dataset...\")\n",
    "        sys.stdout.write(\"| \")\n",
    "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform = transform_train)\n",
    "        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=False, transform = transform_test)\n",
    "        trainset_length = len(trainset)\n",
    "        num_classes = 100\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# Define net\n",
    "net = Wide_ResNet_HRank(depth, widen_factor, dropout, num_classes)\n",
    "file_name = 'wide-resnet-hrank'+str(depth)+'x'+str(widen_factor)+str(dataset)\n",
    "\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m,wide_basic):\n",
    "        m.pruning = False        \n",
    "\n",
    "    if bc:\n",
    "        to_bc = BC(net)\n",
    "        net = to_bc.model\n",
    "    \n",
    "# Test only option\n",
    "if (testOnly):\n",
    "    print('\\n[Test Phase] : Model setup')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        acc = 100.*correct/total\n",
    "        print(\"| Test Result\\tAcc@1: %.2f%%\" %(acc))\n",
    "\n",
    "    sys.exit(0)\n",
    "\n",
    "# Model\n",
    "print('\\n[Phase 2] : Model setup')\n",
    "if(resume):\n",
    "    # Load checkpoint\n",
    "    print('| Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('| Building net type [' + net_type + ']...')\n",
    "    net.apply(conv_init)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "    print('| Going fast AF with C U D A *o* !')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    net.training = True\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate(lr, epoch)))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        if bc:\n",
    "            bc.binarization()\n",
    "            outputs = net(inputs)       # Forward Propagation\\n\",\n",
    "            loss = criterion(outputs,targets)\n",
    "            bc.restore()\n",
    "            loss.backward()\n",
    "            bc.clip()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
    "                %(epoch, num_epochs, batch_idx+1,\n",
    "                    (trainset_lenght//batch_size)+1, loss.item(), 100.*correct/total))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        # Save checkpoint when best model\n",
    "        acc = 100.*correct/total\n",
    "        print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
    "            state = {\n",
    "                    'net':net.module if use_cuda else net,\n",
    "                    'acc':acc,\n",
    "                    'epoch':epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            save_point = './checkpoint/'+dataset+os.sep\n",
    "            if not os.path.isdir(save_point):\n",
    "                os.mkdir(save_point)\n",
    "            torch.save(state, save_point+file_name+'.t7')\n",
    "            best_acc = acc\n",
    "\n",
    "print('\\n[Phase 3] : Training model')\n",
    "print('| Training Epochs = ' + str(num_epochs))\n",
    "print('| Initial Learning Rate = ' + str(lr))\n",
    "print('| Optimizer = ' + str(optim_type))\n",
    "\n",
    "elapsed_time = 0\n",
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    elapsed_time += epoch_time\n",
    "    print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
    "torch.save(net,\"wide_resnet.pth\")\n",
    "print('\\n[Phase 4] : Testing model')\n",
    "print('* Test results : Acc@1 = %.2f%%' %(best_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
