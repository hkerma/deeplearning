{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "WideResNet_Master.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6mhqp_gL0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############### Pytorch CIFAR configuration file ###############\n",
        "import math\n",
        "import functions.BinaryConnect as BC\n",
        "import functions.DataAugmentation as DA\n",
        "from functions.AutoAugment import AutoAugment, Cutout\n",
        "from models.WideResnet_HRank import Wide_ResNet_HRank, wide_basic\n",
        "from torch.nn import init\n",
        "start_epoch = 1\n",
        "num_epochs = 140\n",
        "batch_size = 128\n",
        "optim_type = 'SGD'\n",
        "\n",
        "mean = {\n",
        "    'cifar10': (0.4914, 0.4822, 0.4465),\n",
        "    'cifar100': (0.5071, 0.4867, 0.4408),\n",
        "}\n",
        "\n",
        "std = {\n",
        "    'cifar10': (0.2023, 0.1994, 0.2010),\n",
        "    'cifar100': (0.2675, 0.2565, 0.2761),\n",
        "}\n",
        "\n",
        "# Only for cifar-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def learning_rate(init, epoch):\n",
        "    optim_factor = 0\n",
        "    if(epoch > 120):\n",
        "        optim_factor = 3\n",
        "    elif(epoch > 80):\n",
        "        optim_factor = 2\n",
        "    elif(epoch > 40):\n",
        "        optim_factor = 1\n",
        "\n",
        "    return init*math.pow(0.2, optim_factor)\n",
        "\n",
        "def get_hms(seconds):\n",
        "    m, s = divmod(seconds, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "\n",
        "    return h, m, s\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu45vJRmwWur",
        "colab_type": "code",
        "outputId": "ac795fb4-d57b-44ba-a4ae-a1237c1afb45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "##### TRAINING CELL #####\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "#Parameters settings\n",
        "depth = 40 ##can be 10, 16, 22, 28(default), 34, 40\n",
        "net_type = 'wide-resnet'\n",
        "lr = 0.1\n",
        "widen_factor = 2 #any numer, 10(default)\n",
        "dropout = 0.3\n",
        "dataset = 'cifar10'\n",
        "testOnly = False\n",
        "resume = False\n",
        "bc = False\n",
        "da = True\n",
        "# Hyper Parameter settings\n",
        "use_cuda = torch.cuda.is_available()\n",
        "best_acc = 0\n",
        "\n",
        "# Data Uplaod\n",
        "print('\\n[Phase 1] : Data Preparation')\n",
        "if da:\n",
        "    #print(\"*Using Data Augmentation\")\n",
        "    to_da = DA.DataAugmentation(dataset,aa=True, cut=True)\n",
        "    if (dataset == 'cifar10'):\n",
        "        num_classes = 10\n",
        "    elif (dataset == 'cifar100'):\n",
        "        num_classes = 100\n",
        "    trainset_lenght,trainloader, testloader = to_da.load_data()\n",
        "else:\n",
        "    #print(\\\"| Using no Data Augmentation\")\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean[dataset], std[dataset]),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean[dataset], std[dataset]),\n",
        "    ])\n",
        "    if(dataset == 'cifar10'):\n",
        "        print(\"| Preparing CIFAR-10 dataset...\")\n",
        "        sys.stdout.write(\"| \")\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform = transform_test)\n",
        "        trainset_length = len(trainset)\n",
        "        num_classes = 10\n",
        "    elif(dataset == 'cifar100'):\n",
        "        print(\"| Preparing CIFAR-100 dataset...\")\n",
        "        sys.stdout.write(\"| \")\n",
        "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform = transform_train)\n",
        "        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=False, transform = transform_test)\n",
        "        trainset_length = len(trainset)\n",
        "        num_classes = 100\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Phase 1] : Data Preparation\n",
            "| Preparing CIFAR-10 dataset...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGQYfAMBgL0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define net\n",
        "net = Wide_ResNet_HRank(depth, widen_factor, dropout, num_classes)\n",
        "file_name = 'wide-resnet-hrank'+str(depth)+'x'+str(widen_factor)+str(dataset)\n",
        "\n",
        "\n",
        "for m in net.modules():\n",
        "    if isinstance(m,wide_basic):\n",
        "        m.pruning = False        \n",
        "\n",
        "    if bc:\n",
        "        to_bc = BC(net)\n",
        "        net = to_bc.model\n",
        "    \n",
        "# Test only option\n",
        "if (testOnly):\n",
        "    print('\\n[Test Phase] : Model setup')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
        "    net = checkpoint['net']\n",
        "\n",
        "    if use_cuda:\n",
        "        net.cuda()\n",
        "        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    net.eval()\n",
        "    net.training = False\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        acc = 100.*correct/total\n",
        "        print(\"| Test Result\\tAcc@1: %.2f%%\" %(acc))\n",
        "\n",
        "    sys.exit(0)\n",
        "\n",
        "# Model\n",
        "print('\\n[Phase 2] : Model setup')\n",
        "if(resume):\n",
        "    # Load checkpoint\n",
        "    print('| Resuming from checkpoint...')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
        "    net = checkpoint['net']\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "else:\n",
        "    print('| Building net type [' + net_type + ']...')\n",
        "    net.apply(conv_init)\n",
        "\n",
        "if use_cuda:\n",
        "    net.cuda()\n",
        "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "    cudnn.benchmark = True\n",
        "    print('| Going fast AF with C U D A *o* !')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    net.train()\n",
        "    net.training = True\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate(lr, epoch)))\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = Variable(inputs), Variable(targets)\n",
        "        if bc:\n",
        "            bc.binarization()\n",
        "            outputs = net(inputs)       # Forward Propagation\\n\",\n",
        "            loss = criterion(outputs,targets)\n",
        "            bc.restore()\n",
        "            loss.backward()\n",
        "            bc.clip()\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs,targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (trainset_lenght//batch_size)+1, loss.item(), 100.*correct/total))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    net.training = False\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        # Save checkpoint when best model\n",
        "        acc = 100.*correct/total\n",
        "        print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
        "\n",
        "        if acc > best_acc:\n",
        "            print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "            state = {\n",
        "                    'net':net.module if use_cuda else net,\n",
        "                    'acc':acc,\n",
        "                    'epoch':epoch,\n",
        "            }\n",
        "            if not os.path.isdir('checkpoint'):\n",
        "                os.mkdir('checkpoint')\n",
        "            save_point = './checkpoint/'+dataset+os.sep\n",
        "            if not os.path.isdir(save_point):\n",
        "                os.mkdir(save_point)\n",
        "            torch.save(state, save_point+file_name+'.t7')\n",
        "            best_acc = acc\n",
        "\n",
        "print('\\n[Phase 3] : Training model')\n",
        "print('| Training Epochs = ' + str(num_epochs))\n",
        "print('| Initial Learning Rate = ' + str(lr))\n",
        "print('| Optimizer = ' + str(optim_type))\n",
        "\n",
        "elapsed_time = 0\n",
        "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    elapsed_time += epoch_time\n",
        "    print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
        "torch.save(net,\"wide_resnet.pth\")\n",
        "print('\\n[Phase 4] : Testing model')\n",
        "print('* Test results : Acc@1 = %.2f%%' %(best_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARtPxYXglI8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "329eead2-be0c-499b-84a9-fc765e70398c"
      },
      "source": [
        "#Install the module torch_pruning\n",
        "!pip3 install torch_pruning"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_pruning\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/0e/b436a03f48434235d6aebd1eed8848741ef69a89fac449bbf3fcf8af155f/torch_pruning-0.1.5-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch_pruning) (1.4.0)\n",
            "Installing collected packages: torch-pruning\n",
            "Successfully installed torch-pruning-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gtY3_Z1uWh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def number_of_trainable_params(model):\n",
        "        model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "        return sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOp4uRbkxuoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fine Tuning\n",
        "def learning_rate_ft(init, epoch):\n",
        "    optim_factor = 0\n",
        "    if(epoch > 3):\n",
        "        optim_factor = 3\n",
        "    elif(epoch > 2):\n",
        "        optim_factor = 2\n",
        "    elif(epoch > 1):\n",
        "        optim_factor = 1\n",
        "\n",
        "    return init*math.pow(0.2, optim_factor)\n",
        "    \n",
        "def fine_tuning_train(epoch,net,bc = False, num_epochs = 3, lr = 0.001):\n",
        "    net.train()\n",
        "    net.training = True\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate_ft(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print('\\n => Fine Tuning Epoch #%d, LR=%.4f' %(epoch, learning_rate_ft(lr, epoch)))\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = Variable(inputs), Variable(targets)\n",
        "        if bc:\n",
        "            bc.binarization()\n",
        "            outputs = net(inputs)       # Forward Propagation\\n\",\n",
        "            loss = criterion(outputs,targets)\n",
        "            bc.restore()\n",
        "            loss.backward()\n",
        "            bc.clip()\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs,targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (trainset_lenght//batch_size)+1, loss.item(), 100.*correct/total))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "def fine_tuning_test(epoch,net):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    net.training = False\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        # Save checkpoint when best model\n",
        "        acc = 100.*correct/total\n",
        "        if epoch != 0:\n",
        "          print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
        "\n",
        "        if acc > best_acc:\n",
        "            print('| New Best Accuracy...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "            print('| Saving Pruned Model...')\n",
        "            torch.save(net,\"wide_resnet.pth\")\n",
        "            best_acc = acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzYttVVoCD3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveList(myList,filename):\n",
        "    # the filename should mention the extension 'npy'\n",
        "    np.save(filename,myList)\n",
        "    print(\"Saved successfully!\")\n",
        "\n",
        "def loadList(filename):\n",
        "    # the filename should mention the extension 'npy'\n",
        "    tempNumpyArray=np.load(filename)\n",
        "    return tempNumpyArray.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kk68NiAiHwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hard Pruning\n",
        "from functions.HardPruning import HardPrunning\n",
        "from functions.HRankPruning import HRank\n",
        "from models.Wide_ResNet import Wide_ResNet\n",
        "import torch_pruning as pruning\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "#Params\n",
        "depth = 40\n",
        "net_type = 'wide-resnet'\n",
        "widen_factor = 2 \n",
        "dropout = 0.3\n",
        "dataset = 'cifar10'\n",
        "num_classes = 10\n",
        "\n",
        "file_name = 'wide-resnet-'+str(depth)+'x'+str(widen_factor)\n",
        "\n",
        "\n",
        "#WideResnet 40x2 has 3 layers\n",
        "net = Wide_ResNet(depth, widen_factor, dropout, num_classes)\n",
        "\n",
        "#Pruning ratios for each layer\n",
        "pruning_ratios_layer1 = [[x,0.0,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer2 = [[0.0,x,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer3 = [[0.0,0.0,x] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios = [x for x in np.linspace(0,0.9,10)]\n",
        "\n",
        "#Pruning based on the score of the filters\n",
        "fscore_accuracy_layer1 = []\n",
        "fscore_accuracy_layer2 = []\n",
        "fscore_accuracy_layer3 = []\n",
        "fscore_net_weights_layer1 = []\n",
        "fscore_net_weights_layer2 = []\n",
        "fscore_net_weights_layer3 = []\n",
        "\n",
        "initial_weights = number_of_trainable_params(net)\n",
        "\n",
        "print('[ Weights : {}]'.format(initial_weights))\n",
        "\n",
        "for r in pruning_ratios_layer3:\n",
        "    # Load checkpoint\n",
        "    \n",
        "\n",
        "    print('| Resuming from checkpoint...')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
        "    net = checkpoint['net']\n",
        "    best_acc = -1000\n",
        "    print('\\n[1] PRUNING-----------------------------------------------------------')\n",
        "    print('\\n=> Pruning Layer 2... | Ratio : {}%'.format(r[2]))\n",
        "    fscore = HardPrunning(net,r)\n",
        "    fscore.HardPruning()\n",
        "    removed_weights = number_of_trainable_params(fscore.model)\n",
        "    weights_diff = initial_weights - removed_weights\n",
        "\n",
        "    print('| Weights removed : {} | {}%'.format(weights_diff,int(100 - 100*removed_weights/initial_weights)))\n",
        "    fscore_net_weights_layer3.append(removed_weights)\n",
        "\n",
        "    print('\\n[2] FINE TUNING-------------------------------------------------------')\n",
        "    elapsed_time = 0\n",
        "    for epoch in range(1, 4):\n",
        "        start_time = time.time()\n",
        "\n",
        "        fine_tuning_train(epoch,fscore.model)\n",
        "        fine_tuning_test(epoch, fscore.model)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        elapsed_time += epoch_time\n",
        "        print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
        "\n",
        "    print('\\n[3] TESTING -----------------------------------------------------------')\n",
        "    print('Testing model..')\n",
        "    print('* Test results : Acc@1 = %.2f%%' %(best_acc))\n",
        "    print('\\n ----------------------------------------------------------------------')\n",
        "    fscore_accuracy_layer3.append(best_acc.item())\n",
        "    best_acc = -1000\n",
        "\n",
        "saveList(fscore_accuracy_layer3,\"fscore_accuracy_layer3\")\n",
        "saveList(fscore_net_weights_layer3,\"score_net_weights_layer3\")\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(loadList(\"score_net_weights_layer3.npy\"),loadList(\"fscore_accuracy_layer3.npy\"),)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0sF_tj4m3nX",
        "colab_type": "code",
        "outputId": "9e1315d1-ac31-48b8-a70a-eef4b3993666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Hard Rank Pruning\n",
        "from functions.HRankPruning import HRank\n",
        "from models.WideResnet_HRank import Wide_ResNet_HRank\n",
        "import torch_pruning as pruning\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "#Params\n",
        "depth = 40\n",
        "net_type = 'wide-resnet'\n",
        "widen_factor = 2 \n",
        "dropout = 0.3\n",
        "dataset = 'cifar10'\n",
        "num_classes = 10\n",
        "\n",
        "file_name = 'wide-resnet-'+str(depth)+'x'+str(widen_factor)\n",
        "\n",
        "\n",
        "#WideResnet 40x2 has 3 layers\n",
        "net = Wide_ResNet_HRank(depth, widen_factor, dropout, num_classes)\n",
        "net.cuda()\n",
        "    \n",
        "#Data for net analysis\n",
        "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
        "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
        "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
        "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
        "    all_indices = []\n",
        "    for curclas in range(n_classes):\n",
        "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
        "        indices_curclas = curtargets[0]\n",
        "        indices_subset = indices_curclas[indices_split]\n",
        "        #print(len(indices_subset))\n",
        "        all_indices.append(indices_subset)\n",
        "    all_indices = np.hstack(all_indices)\n",
        "    return Subset(dataset,indices=all_indices)\n",
        "\n",
        "rootdir = './data/'\n",
        "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_scratch,\n",
        "])\n",
        "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
        "subset = generate_subset(dataset=c10test,n_classes=10,reducefactor=20,n_ex_class_init=1000)\n",
        "loader = DataLoader(subset,batch_size=50, num_workers=2)\n",
        "\n",
        "#Pruning ratios for each layer\n",
        "pruning_ratios_layer1 = [[x,0.0,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer2 = [[0.0,x,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer3 = [[0.0,0.0,x] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios = [x for x in np.linspace(0,0.9,10)]\n",
        "\n",
        "#Pruning based on the score of the filters\n",
        "hscore_accuracy_layer1 = []\n",
        "hscore_accuracy_layer2 = []\n",
        "hscore_accuracy_layer3 = []\n",
        "hscore_net_weights_layer1 = []\n",
        "hscore_net_weights_layer2 = []\n",
        "hscore_net_weights_layer3 = []\n",
        "\n",
        "initial_weights = number_of_trainable_params(net)\n",
        "\n",
        "print('[ Weights : {}]'.format(initial_weights))\n",
        "\n",
        "for r in pruning_ratios_layer3:\n",
        "    # Load checkpoint\n",
        "    print('| Resuming from checkpoint...')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
        "    net = checkpoint['net']\n",
        "    best_acc = -1000\n",
        "\n",
        "    print('\\n[1] PRUNING-----------------------------------------------------------')\n",
        "    print('\\n=> Pruning Net... | Layer1 : {}% Layer2 : {}% Layer3 : {}%'.format(r[0]*100,r[1]*100,r[2]*100))\n",
        "    for m in net.modules():\n",
        "        if isinstance(m,wide_basic):\n",
        "            m.pruning = True  \n",
        "    hscore = HRank(net,loader,r)\n",
        "    hscore.HRank()\n",
        "    removed_weights = number_of_trainable_params(hscore.model)\n",
        "    weights_diff = initial_weights - removed_weights\n",
        "    print('| Weights removed : {} | {}%'.format(weights_diff,int(100 - 100*removed_weights/initial_weights)))\n",
        "    hscore_net_weights_layer3.append(removed_weights)\n",
        "\n",
        "    print('\\n[2] FINE TUNING-------------------------------------------------------')\n",
        "    elapsed_time = 0\n",
        "    for m in net.modules():\n",
        "        if isinstance(m,wide_basic):\n",
        "            m.pruning = False  \n",
        "    for epoch in range(1, 4):\n",
        "        start_time = time.time()\n",
        "\n",
        "        fine_tuning_train(epoch,hscore.model)\n",
        "        fine_tuning_test(epoch,hscore.model)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        elapsed_time += epoch_time\n",
        "        print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
        "\n",
        "    print('\\n[3] TESTING -----------------------------------------------------------')\n",
        "    print('Testing model..')\n",
        "    print('* Test results : Acc@1 = %.2f%%' %(best_acc))\n",
        "    print('\\n ----------------------------------------------------------------------')\n",
        "    hscore_accuracy_layer3.append(best_acc.item())\n",
        "    best_acc = -1000\n",
        "\n",
        "saveList(hscore_accuracy_layer3,\"hscore_accuracy_layer3\")\n",
        "saveList(hscore_net_weights_layer3,\"hscore_net_weights_layer3\")\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(loadList(\"hscore_net_weights_layer3.npy\"),loadList(\"hscore_accuracy_layer3.npy\"),)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 40x2\n",
            "Files already downloaded and verified\n",
            "[ Weights : 2246474]\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 0.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 0 | 0%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.3279 Acc@1: 93.054%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.0045 Acc@1: 94.05%\n",
            "| New Best Accuracy...\t\t\tTop1 = 94.05%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:01\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.1601 Acc@1: 93.226%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.1727 Acc@1: 94.36%\n",
            "| New Best Accuracy...\t\t\tTop1 = 94.36%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:02\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.1390 Acc@1: 93.468%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.0808 Acc@1: 94.12%\n",
            "| Elapsed time : 0:03:03\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 94.36%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 10.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 159192 | 7%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.2526 Acc@1: 92.540%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.2036 Acc@1: 93.87%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.87%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:00\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.1906 Acc@1: 92.870%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.4209 Acc@1: 93.93%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.93%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:01\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.1803 Acc@1: 92.988%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.2024 Acc@1: 93.97%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.97%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:03:02\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 93.97%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 20.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 331650 | 14%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.1859 Acc@1: 91.874%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.2966 Acc@1: 93.26%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.26%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:00\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2071 Acc@1: 92.446%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.0611 Acc@1: 93.83%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.83%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:00\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.4153 Acc@1: 92.610%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.0006 Acc@1: 93.84%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.84%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:03:00\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 93.84%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 30.000000000000004%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 504108 | 22%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.3162 Acc@1: 91.284%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.2627 Acc@1: 93.01%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.01%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:59\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2189 Acc@1: 91.956%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.0073 Acc@1: 93.36%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.36%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:58\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.2721 Acc@1: 91.926%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.0043 Acc@1: 93.77%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.77%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:58\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 93.77%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 40.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 676566 | 30%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.3055 Acc@1: 90.424%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.0618 Acc@1: 92.81%\n",
            "| New Best Accuracy...\t\t\tTop1 = 92.81%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:58\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2671 Acc@1: 91.178%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.0315 Acc@1: 93.08%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.08%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:57\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.2876 Acc@1: 91.612%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.1856 Acc@1: 93.26%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.26%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:56\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 93.26%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 50.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 849024 | 37%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.2701 Acc@1: 89.048%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.4410 Acc@1: 92.62%\n",
            "| New Best Accuracy...\t\t\tTop1 = 92.62%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:57\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.1638 Acc@1: 90.184%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.5708 Acc@1: 92.91%\n",
            "| New Best Accuracy...\t\t\tTop1 = 92.91%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:55\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.2509 Acc@1: 90.650%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.0127 Acc@1: 93.16%\n",
            "| New Best Accuracy...\t\t\tTop1 = 93.16%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:52\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 93.16%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 60.00000000000001%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 987444 | 43%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.3386 Acc@1: 88.056%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.2961 Acc@1: 91.78%\n",
            "| New Best Accuracy...\t\t\tTop1 = 91.78%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:57\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2850 Acc@1: 89.628%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.8595 Acc@1: 92.49%\n",
            "| New Best Accuracy...\t\t\tTop1 = 92.49%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:55\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.3171 Acc@1: 90.032%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.1678 Acc@1: 92.48%\n",
            "| Elapsed time : 0:02:52\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 92.49%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 70.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 1137399 | 50%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.3904 Acc@1: 86.766%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.9250 Acc@1: 90.72%\n",
            "| New Best Accuracy...\t\t\tTop1 = 90.72%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:57\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2456 Acc@1: 88.416%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.4417 Acc@1: 91.13%\n",
            "| New Best Accuracy...\t\t\tTop1 = 91.13%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:53\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.4745 Acc@1: 89.030%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.4105 Acc@1: 91.56%\n",
            "| New Best Accuracy...\t\t\tTop1 = 91.56%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:50\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 91.56%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 80.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 1287354 | 57%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.4008 Acc@1: 84.472%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.2268 Acc@1: 90.23%\n",
            "| New Best Accuracy...\t\t\tTop1 = 90.23%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:56\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.2628 Acc@1: 87.084%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.3154 Acc@1: 91.21%\n",
            "| New Best Accuracy...\t\t\tTop1 = 91.21%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:52\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.4254 Acc@1: 87.520%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.2746 Acc@1: 91.32%\n",
            "| New Best Accuracy...\t\t\tTop1 = 91.32%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:49\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 91.32%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0.0% Layer2 : 0.0% Layer3 : 90.0%\n",
            "Sending data through the net...\n",
            "Weak filters have been identified ! \n",
            "The net has been pruned ! \n",
            "| Weights removed : 1437309 | 63%\n",
            "\n",
            "[2] FINE TUNING-------------------------------------------------------\n",
            "\n",
            " => Fine Tuning Epoch #1, LR=0.0010\n",
            "| Epoch [  1/  3] Iter[391/391]\t\tLoss: 0.5403 Acc@1: 80.304%\n",
            "| Validation Epoch #1\t\t\tLoss: 0.4935 Acc@1: 87.64%\n",
            "| New Best Accuracy...\t\t\tTop1 = 87.64%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:00:55\n",
            "\n",
            " => Fine Tuning Epoch #2, LR=0.0002\n",
            "| Epoch [  2/  3] Iter[391/391]\t\tLoss: 0.5730 Acc@1: 84.532%\n",
            "| Validation Epoch #2\t\t\tLoss: 0.1193 Acc@1: 88.77%\n",
            "| New Best Accuracy...\t\t\tTop1 = 88.77%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:01:51\n",
            "\n",
            " => Fine Tuning Epoch #3, LR=0.0000\n",
            "| Epoch [  3/  3] Iter[391/391]\t\tLoss: 0.5360 Acc@1: 85.068%\n",
            "| Validation Epoch #3\t\t\tLoss: 0.6286 Acc@1: 89.14%\n",
            "| New Best Accuracy...\t\t\tTop1 = 89.14%\n",
            "| Saving Pruned Model...\n",
            "| Elapsed time : 0:02:47\n",
            "\n",
            "[3] TESTING -----------------------------------------------------------\n",
            "Testing model..\n",
            "* Test results : Acc@1 = 89.14%\n",
            "\n",
            " ----------------------------------------------------------------------\n",
            "Saved successfully!\n",
            "Saved successfully!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEFCAYAAAD69rxNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX8kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5y_YIsPTWZy",
        "colab_type": "code",
        "outputId": "abe510c6-8483-4b66-ab81-b541f60015ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loadList(\"hscore_net_weights_layer3.npy\"),loadList(\"hscore_accuracy_layer3.npy\"))\n",
        "plt.plot(loadList(\"score_net_weights_layer3.npy\"),loadList(\"fscore_accuracy_layer3.npy\"))\n",
        "plt.show()\n",
        "\n",
        "print(loadList(\"hscore_net_weights_layer3.npy\"))\n",
        "print(loadList(\"score_net_weights_layer3.npy\"))\n",
        "\n",
        "plt.plot(loadList(\"hscore_net_weights_layer2.npy\"),loadList(\"hscore_accuracy_layer2.npy\"))\n",
        "plt.plot(loadList(\"score_net_weights_layer2.npy\"),loadList(\"fscore_accuracy_layer2.npy\"))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(loadList(\"hscore_net_weights_layer1.npy\"),loadList(\"hscore_accuracy_layer1.npy\"))\n",
        "plt.plot(loadList(\"score_net_weights_layer1.npy\"),loadList(\"fscore_accuracy_layer1.npy\"))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEFCAYAAAD69rxNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[2246474, 2087282, 1914824, 1742366, 1569908, 1397450, 1259030, 1109075, 959120, 809165]\n",
            "[2246474, 2087282, 1914824, 1742366, 1569908, 1397450, 1238258, 1065800, 893342, 720884]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzoLeGGNinAW9McbEuP8HtHeVsCCVP5EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyeWJmoJJ-D7",
        "colab_type": "code",
        "outputId": "4f6f239d-ab81-4d7d-84fe-90965109d49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  #Iterative pruning\n",
        "#Method : Hard Pruning based on the score of the filters\n",
        "from functions.HardPruningIter import HardPrunningIter\n",
        "from models.Wide_ResNet import Wide_ResNet\n",
        "import torch_pruning as pruning\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "#Params\n",
        "depth = 40\n",
        "net_type = 'wide-resnet'\n",
        "widen_factor = 2 \n",
        "dropout = 0.3\n",
        "dataset = 'cifar10'\n",
        "num_classes = 10\n",
        "file_name = 'wide-resnet-'+str(depth)+'x'+str(widen_factor)\n",
        "\n",
        "#WideResnet 40x2 has 3 layers\n",
        "net = Wide_ResNet(depth, widen_factor, dropout, num_classes)\n",
        "\n",
        "#Pruning ratios for each layer\n",
        "pruning_ratios_layer1 = [[x,0.0,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer2 = [[0.0,x,0.0] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios_layer3 = [[0.0,0.0,x] for x in np.linspace(0,0.9,10)]\n",
        "pruning_ratios = [x for x in np.linspace(0,0.9,10)]\n",
        "\n",
        "#Pruning based on the score of the filters\n",
        "fscore_iter_accuracy_layer1 = []\n",
        "fscore_iter_accuracy_layer2 = []\n",
        "fscore_iter_accuracy_layer3 = []\n",
        "score_iter_net_weights_layer1 = []\n",
        "score_iter_net_weights_layer2 = []\n",
        "score_iter_net_weights_layer3 = []\n",
        "initial_weights = number_of_trainable_params(net)\n",
        "\n",
        "print('[ Weights : {}]'.format(initial_weights))\n",
        "\n",
        "for r in pruning_ratios_layer1:\n",
        "    print('| Resuming from checkpoint...')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
        "    net = checkpoint['net']\n",
        "\n",
        "    fscore_iter = HardPrunningIter(net,r)\n",
        "    fscore_iter.pruning_and_training(testloader,trainloader)\n",
        "    \n",
        "    print(fscore_iter.best_acc[-1])\n",
        "    print(fscore_iter.net_weights[-1])\n",
        "\n",
        "    fscore_iter_accuracy_layer1.append(fscore_iter.best_acc[-1])\n",
        "    score_iter_net_weights.append(fscore_iter.net_weights[-1])\n",
        "\n",
        "\n",
        "saveList(fscore_iter_accuracy_layer1,\"fscore_iter_accuracy_layer1\")\n",
        "saveList(score_iter_net_weights_layer1,\"score_iter_net_weights_layer1\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 40x2\n",
            "[ Weights : 2246474]\n",
            "| Resuming from checkpoint...\n",
            "\n",
            "[1] PRUNING | ITER : 1/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 19908\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2226566]| Iteration [  1] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1328 Acc@1: 93.014%\n",
            " | Test 93.94000244140625 \n",
            "| New Best Accuracy...\t\t\tTop1 = 93.94%\n",
            "| Saving Pruned Model...\n",
            "\n",
            "[1] PRUNING | ITER : 2/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 39816\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2206658]| Iteration [  2] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1491 Acc@1: 92.976%\n",
            " | Test 94.1500015258789 \n",
            "| New Best Accuracy...\t\t\tTop1 = 94.15%\n",
            "| Saving Pruned Model...\n",
            "\n",
            "[1] PRUNING | ITER : 3/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 59724\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2186750]| Iteration [  3] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2097 Acc@1: 92.938%\n",
            " | Test 93.95999908447266 \n",
            "\n",
            "[1] PRUNING | ITER : 4/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 79632\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2166842]| Iteration [  4] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3160 Acc@1: 92.878%\n",
            " | Test 94.05000305175781 \n",
            "\n",
            "[1] PRUNING | ITER : 5/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 99540\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2146934]| Iteration [  5] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1319 Acc@1: 92.896%\n",
            " | Test 93.83000183105469 \n",
            "\n",
            "[1] PRUNING | ITER : 6/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 119448\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2127026]| Iteration [  6] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2164 Acc@1: 93.074%\n",
            " | Test 93.72000122070312 \n",
            "\n",
            "[1] PRUNING | ITER : 7/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 139356\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2107118]| Iteration [  7] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1871 Acc@1: 92.876%\n",
            " | Test 93.80999755859375 \n",
            "\n",
            "[1] PRUNING | ITER : 8/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 159264\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2087210]| Iteration [  8] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1621 Acc@1: 92.690%\n",
            " | Test 94.01000213623047 \n",
            "\n",
            "[1] PRUNING | ITER : 9/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 179172\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2067302]| Iteration [  9] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1471 Acc@1: 92.944%\n",
            " | Test 94.11000061035156 \n",
            "\n",
            "[1] PRUNING | ITER : 10/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 199080\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2047394]| Iteration [ 10] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2011 Acc@1: 92.994%\n",
            " | Test 94.08000183105469 \n",
            "\n",
            "[1] PRUNING | ITER : 11/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 218988\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2027486]| Iteration [ 11] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2063 Acc@1: 92.886%\n",
            " | Test 93.83000183105469 \n",
            "\n",
            "[1] PRUNING | ITER : 12/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 238896\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [2007578]| Iteration [ 12] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2187 Acc@1: 92.840%\n",
            " | Test 93.66999816894531 \n",
            "\n",
            "[1] PRUNING | ITER : 13/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 258804\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1987670]| Iteration [ 13] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2009 Acc@1: 92.924%\n",
            " | Test 93.83999633789062 \n",
            "\n",
            "[1] PRUNING | ITER : 14/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 278712\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1967762]| Iteration [ 14] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1870 Acc@1: 92.684%\n",
            " | Test 93.5999984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 15/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 298620\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1947854]| Iteration [ 15] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2650 Acc@1: 92.758%\n",
            " | Test 93.61000061035156 \n",
            "\n",
            "[1] PRUNING | ITER : 16/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 318528\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1927946]| Iteration [ 16] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1151 Acc@1: 92.946%\n",
            " | Test 93.58000183105469 \n",
            "\n",
            "[1] PRUNING | ITER : 17/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 338436\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1908038]| Iteration [ 17] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1238 Acc@1: 92.854%\n",
            " | Test 93.69000244140625 \n",
            "\n",
            "[1] PRUNING | ITER : 18/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 358344\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1888130]| Iteration [ 18] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1008 Acc@1: 92.760%\n",
            " | Test 93.81999969482422 \n",
            "\n",
            "[1] PRUNING | ITER : 19/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 378252\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1868222]| Iteration [ 19] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2194 Acc@1: 92.870%\n",
            " | Test 94.05000305175781 \n",
            "\n",
            "[1] PRUNING | ITER : 20/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 398160\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1848314]| Iteration [ 20] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1116 Acc@1: 92.542%\n",
            " | Test 93.69000244140625 \n",
            "\n",
            "[1] PRUNING | ITER : 21/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 418068\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1828406]| Iteration [ 21] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2019 Acc@1: 92.782%\n",
            " | Test 93.30000305175781 \n",
            "\n",
            "[1] PRUNING | ITER : 22/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 437976\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1808498]| Iteration [ 22] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2474 Acc@1: 92.682%\n",
            " | Test 94.0999984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 23/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 457884\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1788590]| Iteration [ 23] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1704 Acc@1: 92.826%\n",
            " | Test 93.41999816894531 \n",
            "\n",
            "[1] PRUNING | ITER : 24/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 477792\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1768682]| Iteration [ 24] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1462 Acc@1: 92.504%\n",
            " | Test 93.80999755859375 \n",
            "\n",
            "[1] PRUNING | ITER : 25/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 497700\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1748774]| Iteration [ 25] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3234 Acc@1: 92.516%\n",
            " | Test 93.69999694824219 \n",
            "\n",
            "[1] PRUNING | ITER : 26/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 517608\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1728866]| Iteration [ 26] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1986 Acc@1: 92.392%\n",
            " | Test 92.93000030517578 \n",
            "\n",
            "[1] PRUNING | ITER : 27/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 537516\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1708958]| Iteration [ 27] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2683 Acc@1: 92.538%\n",
            " | Test 92.94000244140625 \n",
            "\n",
            "[1] PRUNING | ITER : 28/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 557424\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1689050]| Iteration [ 28] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2133 Acc@1: 92.472%\n",
            " | Test 92.69999694824219 \n",
            "\n",
            "[1] PRUNING | ITER : 29/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 577332\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1669142]| Iteration [ 29] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2723 Acc@1: 92.560%\n",
            " | Test 92.9800033569336 \n",
            "\n",
            "[1] PRUNING | ITER : 30/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 597240\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1649234]| Iteration [ 30] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2578 Acc@1: 92.344%\n",
            " | Test 93.27999877929688 \n",
            "\n",
            "[1] PRUNING | ITER : 31/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 617148\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1629326]| Iteration [ 31] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2427 Acc@1: 92.288%\n",
            " | Test 92.91999816894531 \n",
            "\n",
            "[1] PRUNING | ITER : 32/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 637056\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1609418]| Iteration [ 32] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1977 Acc@1: 92.244%\n",
            " | Test 92.5199966430664 \n",
            "\n",
            "[1] PRUNING | ITER : 33/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 656964\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1589510]| Iteration [ 33] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.4827 Acc@1: 92.264%\n",
            " | Test 93.06999969482422 \n",
            "\n",
            "[1] PRUNING | ITER : 34/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 676872\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1569602]| Iteration [ 34] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3270 Acc@1: 92.076%\n",
            " | Test 92.68000030517578 \n",
            "\n",
            "[1] PRUNING | ITER : 35/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 696780\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1549694]| Iteration [ 35] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2397 Acc@1: 92.328%\n",
            " | Test 92.66999816894531 \n",
            "\n",
            "[1] PRUNING | ITER : 36/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 716688\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1529786]| Iteration [ 36] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3229 Acc@1: 92.104%\n",
            " | Test 92.66999816894531 \n",
            "\n",
            "[1] PRUNING | ITER : 37/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 736596\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1509878]| Iteration [ 37] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3549 Acc@1: 91.924%\n",
            " | Test 93.01000213623047 \n",
            "\n",
            "[1] PRUNING | ITER : 38/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 756504\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1489970]| Iteration [ 38] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1371 Acc@1: 91.764%\n",
            " | Test 93.08999633789062 \n",
            "\n",
            "[1] PRUNING | ITER : 39/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 776412\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1470062]| Iteration [ 39] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3415 Acc@1: 91.858%\n",
            " | Test 92.94999694824219 \n",
            "\n",
            "[1] PRUNING | ITER : 40/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 796320\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1450154]| Iteration [ 40] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2705 Acc@1: 91.946%\n",
            " | Test 93.19000244140625 \n",
            "\n",
            "[1] PRUNING | ITER : 41/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 816228\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1430246]| Iteration [ 41] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1902 Acc@1: 91.564%\n",
            " | Test 92.31999969482422 \n",
            "\n",
            "[1] PRUNING | ITER : 42/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 836136\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1410338]| Iteration [ 42] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1689 Acc@1: 91.760%\n",
            " | Test 92.6500015258789 \n",
            "\n",
            "[1] PRUNING | ITER : 43/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 856044\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1390430]| Iteration [ 43] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3348 Acc@1: 91.658%\n",
            " | Test 93.04000091552734 \n",
            "\n",
            "[1] PRUNING | ITER : 44/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 875952\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1370522]| Iteration [ 44] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1836 Acc@1: 91.484%\n",
            " | Test 92.58000183105469 \n",
            "\n",
            "[1] PRUNING | ITER : 45/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 895860\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1350614]| Iteration [ 45] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2268 Acc@1: 91.420%\n",
            " | Test 92.5999984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 46/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 915768\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1330706]| Iteration [ 46] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3281 Acc@1: 91.208%\n",
            " | Test 91.4800033569336 \n",
            "\n",
            "[1] PRUNING | ITER : 47/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 935676\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1310798]| Iteration [ 47] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3268 Acc@1: 91.084%\n",
            " | Test 92.05999755859375 \n",
            "\n",
            "[1] PRUNING | ITER : 48/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 955584\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1290890]| Iteration [ 48] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1850 Acc@1: 90.938%\n",
            " | Test 91.8499984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 49/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 968850\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1277624]| Iteration [ 49] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3208 Acc@1: 90.940%\n",
            " | Test 92.56999969482422 \n",
            "\n",
            "[1] PRUNING | ITER : 50/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 982116\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1264358]| Iteration [ 50] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1983 Acc@1: 90.828%\n",
            " | Test 92.37999725341797 \n",
            "\n",
            "[1] PRUNING | ITER : 51/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 995382\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1251092]| Iteration [ 51] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2169 Acc@1: 91.024%\n",
            " | Test 92.37000274658203 \n",
            "\n",
            "[1] PRUNING | ITER : 52/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1008648\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1237826]| Iteration [ 52] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.1541 Acc@1: 91.132%\n",
            " | Test 92.01000213623047 \n",
            "\n",
            "[1] PRUNING | ITER : 53/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1021914\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1224560]| Iteration [ 53] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2584 Acc@1: 91.110%\n",
            " | Test 92.58999633789062 \n",
            "\n",
            "[1] PRUNING | ITER : 54/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1035180\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1211294]| Iteration [ 54] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.4096 Acc@1: 91.308%\n",
            " | Test 92.5999984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 55/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1048446\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1198028]| Iteration [ 55] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2642 Acc@1: 91.258%\n",
            " | Test 91.8499984741211 \n",
            "\n",
            "[1] PRUNING | ITER : 56/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1061712\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1184762]| Iteration [ 56] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.2172 Acc@1: 91.016%\n",
            " | Test 92.23999786376953 \n",
            "\n",
            "[1] PRUNING | ITER : 57/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1074978\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1171496]| Iteration [ 57] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3695 Acc@1: 91.066%\n",
            " | Test 92.51000213623047 \n",
            "\n",
            "[1] PRUNING | ITER : 58/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1088244\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1158230]| Iteration [ 58] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.0949 Acc@1: 91.176%\n",
            " | Test 92.38999938964844 \n",
            "\n",
            "[1] PRUNING | ITER : 59/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1101510\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1144964]| Iteration [ 59] Epoch [  2/  2] Iter[391/391]\t\tLoss: 0.3164 Acc@1: 91.050%\n",
            " | Test 92.13999938964844 \n",
            "\n",
            "[1] PRUNING | ITER : 60/115-----------------------------------------------------------\n",
            "\n",
            "=> Pruning Net... | Layer1 : 0% Layer2 : 75.0% Layer3 : 90.0%\n",
            "Removed weights : 1114776\n",
            "\n",
            "[2] FINE TUNING----------------------------------------------------------------------\n",
            "Trainable params [1131698]| Iteration [ 60] Epoch [  1/  2] Iter[376/391]\t\tLoss: 0.2843 Acc@1: 90.976%"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}