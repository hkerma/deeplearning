{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "### WIDE RESNET IMPLEMENTATION ###\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class wide_basic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_basic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4)/6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
    "        nStages = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = conv3x3(3,nStages[0])\n",
    "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
    "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
    "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net=Wide_ResNet(28, 10, 0.3, 10)\n",
    "    y = net(Variable(torch.randn(1,3,32,32)))\n",
    "\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Pytorch CIFAR configuration file ###############\n",
    "import math\n",
    "\n",
    "start_epoch = 1\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "optim_type = 'SGD'\n",
    "\n",
    "mean = {\n",
    "    'cifar10': (0.4914, 0.4822, 0.4465),\n",
    "    'cifar100': (0.5071, 0.4867, 0.4408),\n",
    "}\n",
    "\n",
    "std = {\n",
    "    'cifar10': (0.2023, 0.1994, 0.2010),\n",
    "    'cifar100': (0.2675, 0.2565, 0.2761),\n",
    "}\n",
    "\n",
    "# Only for cifar-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if(epoch > 160):\n",
    "        optim_factor = 3\n",
    "    elif(epoch > 120):\n",
    "        optim_factor = 2\n",
    "    elif(epoch > 60):\n",
    "        optim_factor = 1\n",
    "\n",
    "    return init*math.pow(0.2, optim_factor)\n",
    "\n",
    "def get_hms(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "\n",
    "    return h, m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Phase 1] : Data Preparation\n",
      "| Preparing CIFAR-10 dataset...\n",
      "| Files already downloaded and verified\n",
      "| Wide-Resnet 40x2\n",
      "\n",
      "[Phase 2] : Model setup\n",
      "| Building net type [wide-resnet]...\n",
      "| Going fast AF with C U D A *o* !\n",
      "\n",
      "[Phase 3] : Training model\n",
      "| Training Epochs = 200\n",
      "| Initial Learning Rate = 0.1\n",
      "| Optimizer = SGD\n",
      "\n",
      "=> Training Epoch #1, LR=0.1000\n",
      "| Epoch [  1/200] Iter[391/391]\t\tLoss: 1.2877 Acc@1: 38.544%\n",
      "| Validation Epoch #1\t\t\tLoss: 1.4315 Acc@1: 51.48%\n",
      "| Saving Best model...\t\t\tTop1 = 51.48%\n",
      "| Elapsed time : 0:00:59\n",
      "\n",
      "=> Training Epoch #2, LR=0.1000\n",
      "| Epoch [  2/200] Iter[391/391]\t\tLoss: 0.9578 Acc@1: 58.736%\n",
      "| Validation Epoch #2\t\t\tLoss: 1.1576 Acc@1: 60.03%\n",
      "| Saving Best model...\t\t\tTop1 = 60.03%\n",
      "| Elapsed time : 0:01:58\n",
      "\n",
      "=> Training Epoch #3, LR=0.1000\n",
      "| Epoch [  3/200] Iter[212/391]\t\tLoss: 0.8180 Acc@1: 64.623%"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Parameters settings\n",
    "depth = 40 ##can be 10, 16, 22, 28(default), 34, 40\n",
    "net_type = 'wide-resnet'\n",
    "lr = 0.1\n",
    "widen_factor = 2 #any numer, 10(default)\n",
    "dropout = 0.3\n",
    "dataset = 'cifar10'\n",
    "testOnly = False\n",
    "resume = False\n",
    "\n",
    "# Hyper Parameter settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "best_acc = 0\n",
    "\n",
    "# Data Uplaod\n",
    "print('\\n[Phase 1] : Data Preparation')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean[dataset], std[dataset]),\n",
    "]) # meanstd transformation\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean[dataset], std[dataset]),\n",
    "])\n",
    "\n",
    "if(dataset == 'cifar10'):\n",
    "    print(\"| Preparing CIFAR-10 dataset...\")\n",
    "    sys.stdout.write(\"| \")\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
    "    num_classes = 10\n",
    "elif(dataset == 'cifar100'):\n",
    "    print(\"| Preparing CIFAR-100 dataset...\")\n",
    "    sys.stdout.write(\"| \")\n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=False, transform=transform_test)\n",
    "    num_classes = 100\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define net\n",
    "net = Wide_ResNet(depth, widen_factor, dropout, num_classes)\n",
    "file_name = 'wide-resnet-'+str(depth)+'x'+str(widen_factor)\n",
    "\n",
    "\n",
    "# Test only option\n",
    "if (testOnly):\n",
    "    print('\\n[Test Phase] : Model setup')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        acc = 100.*correct/total\n",
    "        print(\"| Test Result\\tAcc@1: %.2f%%\" %(acc))\n",
    "\n",
    "    sys.exit(0)\n",
    "\n",
    "# Model\n",
    "print('\\n[Phase 2] : Model setup')\n",
    "if(resume):\n",
    "    # Load checkpoint\n",
    "    print('| Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: No checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/'+dataset+os.sep+file_name+'.t7')\n",
    "    net = checkpoint['net']\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('| Building net type [' + net_type + ']...')\n",
    "    net.apply(conv_init)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "    print('| Going fast AF with C U D A *o* !')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    net.training = True\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate(lr, epoch)))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)               # Forward Propagation\n",
    "        loss = criterion(outputs, targets)  # Loss\n",
    "        loss.backward()  # Backward Propagation\n",
    "        optimizer.step() # Optimizer update\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
    "                %(epoch, num_epochs, batch_idx+1,\n",
    "                    (len(trainset)//batch_size)+1, loss.item(), 100.*correct/total))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    net.training = False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        # Save checkpoint when best model\n",
    "        acc = 100.*correct/total\n",
    "        print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
    "            state = {\n",
    "                    'net':net.module if use_cuda else net,\n",
    "                    'acc':acc,\n",
    "                    'epoch':epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            save_point = './checkpoint/'+dataset+os.sep\n",
    "            if not os.path.isdir(save_point):\n",
    "                os.mkdir(save_point)\n",
    "            torch.save(state, save_point+file_name+'.t7')\n",
    "            best_acc = acc\n",
    "\n",
    "print('\\n[Phase 3] : Training model')\n",
    "print('| Training Epochs = ' + str(num_epochs))\n",
    "print('| Initial Learning Rate = ' + str(lr))\n",
    "print('| Optimizer = ' + str(optim_type))\n",
    "\n",
    "elapsed_time = 0\n",
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    elapsed_time += epoch_time\n",
    "    print('| Elapsed time : %d:%02d:%02d'  %(get_hms(elapsed_time)))\n",
    "\n",
    "print('\\n[Phase 4] : Testing model')\n",
    "print('* Test results : Acc@1 = %.2f%%' %(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
